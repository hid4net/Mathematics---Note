
<h1 style="text-align:center">概率与统计</h1>

--------------------------------------------------------------------------------
<!-- @import "[TOC]" {cmd="toc" depthFrom=1 depthTo=6 orderedList=false} -->

<!-- code_chunk_output -->

- [1. 基本概念](#-1-基本概念-)
  - [1.1. 样本空间、随机事件](#-11-样本空间-随机事件-)
  - [1.2. 条件概率](#-12-条件概率-)
  - [1.3. 独立性](#-13-独立性-)
- [2. 随机变量及其分布](#-2-随机变量及其分布-)
  - [2.1. 离散型随机变量及其分布](#-21-离散型随机变量及其分布-)
  - [2.2. 连续型随机变量及其分布](#-22-连续型随机变量及其分布-)
  - [2.3. 二维随机变量, $n$ 维随机变量](#-23-二维随机变量-n-维随机变量-)
  - [2.4. 边缘分布](#-24-边缘分布-)
  - [2.5. 条件分布](#-25-条件分布-)
  - [2.6. 相互独立的随机变量](#-26-相互独立的随机变量-)
  - [2.7. 两个随机变量的函数的分布](#-27-两个随机变量的函数的分布-)
- [3. 随机变量的数学特征](#-3-随机变量的数学特征-)
  - [3.1. 数学期望](#-31-数学期望-)
  - [3.2. 方差](#-32-方差-)
  - [3.3. 常见分布的期望和方差](#-33-常见分布的期望和方差-)
  - [3.4. 协方差与相关系数](#-34-协方差与相关系数-)
  - [3.5. 矩, 协方差矩阵](#-35-矩-协方差矩阵-)
  - [3.6. 其它特征](#-36-其它特征-)
- [4. 大数定律及中心极限定理](#-4-大数定律及中心极限定理-)
  - [4.1. 大数定律](#-41-大数定律-)
  - [4.2. 中心极限定理](#-42-中心极限定理-)
- [5. 样本及抽样分布](#-5-样本及抽样分布-)
  - [5.1. 随机样本](#-51-随机样本-)
  - [5.2. 抽样分布](#-52-抽样分布-)
    - [5.2.1. $\chi^2$ 分布 (卡方分布)](#-521-chi2-分布-卡方分布-)
    - [5.2.2. $t$ 分布](#-522-t-分布-)
    - [5.2.3. $F$ 分布](#-523-f-分布-)
    - [5.2.4. 正态总体的样本均值与样本方差的分布](#-524-正态总体的样本均值与样本方差的分布-)
- [6. 参数估计](#-6-参数估计-)
  - [6.1. 点估计](#-61-点估计-)
    - [6.1.1. 矩估计法](#-611-矩估计法-)
    - [6.1.2. 最大似然估计](#-612-最大似然估计-)
    - [6.1.3. 常见分布的估计](#-613-常见分布的估计-)
  - [6.2. 估计量的评选标准](#-62-估计量的评选标准-)
  - [6.3. 区间估计](#-63-区间估计-)
    - [6.3.1. 置信区间](#-631-置信区间-)
    - [6.3.2. 单侧置信区间](#-632-单侧置信区间-)
    - [6.3.3. 正态总体的区间估计](#-633-正态总体的区间估计-)
- [7. 假设检验](#-7-假设检验-)
  - [7.1. 基本概念](#-71-基本概念-)
  - [7.2. 基本步骤](#-72-基本步骤-)
  - [7.3. 正态总体的假设检验](#-73-正态总体的假设检验-)
  - [7.4. 样本容量的选取](#-74-样本容量的选取-)
  - [7.5. 分布拟合检验](#-75-分布拟合检验-)
    - [7.5.1. 单个分布的 $\chi^2$ 拟合检验法](#-751-单个分布的-chi2-拟合检验法-)
    - [7.5.2. 分布族的 $\chi^2$ 拟合检验](#-752-分布族的-chi2-拟合检验-)
    - [7.5.3. 偏度、峰度检验](#-753-偏度-峰度检验-)
  - [7.6. 检验问题的 $p$ 值法](#-76-检验问题的-p-值法-)
- [8. 方差分析及线性回归](#-8-方差分析及线性回归-)
  - [8.1. 单因素实验的方差分析](#-81-单因素实验的方差分析-)
  - [8.2. 双因素试验的方差分析](#-82-双因素试验的方差分析-)
    - [8.2.1. 双因素等重复试验](#-821-双因素等重复试验-)
    - [8.2.2. 双因素无重复试验](#-822-双因素无重复试验-)
  - [8.3. 一元线性回归](#-83-一元线性回归-)
  - [8.4. 多元线性回归](#-84-多元线性回归-)

<!-- /code_chunk_output -->

--------------------------------------------------------------------------------
# 1. 基本概念

## 1.1. 样本空间、随机事件
* **样本空间**: 随机试验 $E$ 的所有可能结果组成的集合, 记为 $S$
* **样本点**: 样本空间的元素, $E$ 的每个结果
* **随机事件** (简称**事件**), **必然事件**, **不可能事件**
* **事件的关系**: 相等, 和事件, 积事件, 差事件, 互斥, 逆事件 (对立事件)
* **频数**, **频率**
* **概率**: 设 $E$ 是随机实验, $S$ 是它的样本空间, 对于 $E$ 的每一事件 $A$ 赋予一个实数, 记为 $P(A)$
    1. **非负性**: 对于每一个事件 $A$, 有 $P(A) \geqslant 0$
    1. **规范性**: 对于必然事件 $S$, 有 $P(S) = 1$
    1. **可列可加性**: 设 $A_1, A_2, \cdots$ 是两两互不相容的事件, 即对于 $A_i A_j = \varnothing, i \ne j, i,j = 1,2,\cdots$, 有 $P(A_1 \cup A_2 \cup \cdots) = P(A_1) + P(A_2) + \cdots$
    * **性质**:
        1. $P(\varnothing) = 0$
        1. **有限可加性**: 若 $A_1, A_2, \cdots, A_n$ 是两两互不相容的事件, 则有 $P(A_1 \cup A_2 \cup \cdots \cup A_n) = P(A_1) + P(A_2) + \cdots + P(A_n)$
        1. 设 $A, B$ 是两个事件, 若 $A \subset B$, 则有 $$\begin{aligned} P(B-A) &= P(B) - P(A) \\ P(B) &\geqslant P(A) \end{aligned}$$
        1. 对于任一事件 $A$, $P(A) \leqslant 1$
        1. **逆事件的概率**: 对于任一事件 $A$ 有 $P(\bar A) = 1 - P(A)$
        1. **加法公式**: $P(A \cup B) = P(A) + P(B) - P(AB)$

## 1.2. 条件概率
* **定义**: 设 $A,B$ 是两个事件, 且 $P(A) > 0$, 称 $P(B|A) = \dfrac{P(AB)}{P(A)}$ 为事件 $A$ 发生的条件下 $B$ 发生的条件概率
* **性质**:
    1. **非负性**: 对于每一个事件 $B$, 有 $P(B|A) \geqslant 0$
    1. **规范性**: 对于必然事件 $S$, 有 $P(S|A) = 1$
    1. **可列可加性**: 设 $B_1, B_2, \cdots$ 是两两互不相容的事件, 则有 $\displaystyle P(\bigcup _{i=1}^{\infin} B_i|A) = \sum _{i=1}^{\infin} P(B_i |A)$
* **定理**:
    1. **乘法定理**: 设 $P(A) > 0$, 则有 $P(AB) = P(B|A) P(A)$
    1. **全概率公式**: 设试验 $E$ 的样本空间为 $S$, $A$ 为 $E$ 的事件, $B_1, B_2, \cdots, B_n$ 为 $S$ 的一个划分, 且 $P(B_i) > 0 (i = 1,2,\cdots,n)$, 则 $$P(A) = P(A|B_1)P(B_1) + P(A|B_2)P(B_2) + \cdots + P(A|B_n)P(B_n)$$
    1. **贝叶斯 (Bayes) 公式**: 设试验 $E$ 的样本空间为 $S$, $A$ 为 $E$ 的事件, $B_1, B_2, \cdots, B_n$ 为 $S$ 的一个划分, 且 $P(A) > 0, P(B_i) > 0 (i = 1,2,\cdots,n)$, 则 $$P(B_i|A) = \dfrac{P(A|B_i)P(B_i)}{\displaystyle \sum _{j=1}^{n}P(A|B_j)P(B_j)}, \quad i=1,2,\cdots,n$$

## 1.3. 独立性
* **定义**: 设 $A, B$ 是两事件, 如果满足等式 $P(AB) = P(A) P(B)$, 则称两事件**相互独立**, 简称**独立**; 一般地, 设 $A_1, A_2, \cdots, A_n$ 是 $n (n \geqslant 2)$ 个事件, 如果对于其中任意 2 个, 任意 3 个, $\cdots$, 任意 $n$ 个事件的积事件的概率, 都等于各事件概率之积, 则称事件 $A_1, A_2, \cdots, A_n$ **相互独立**
* **定理**:
    1. 设 $A, B$ 是两事件, 且 $P(A) > 0$, 若 $A, B$ 相互独立, 则 $P(B|A) = P(B)$, 反之亦然;
    1. 若事件 $A, B$ 相互独立, 则下列各对事件也相互独立: $A$ 与 $\bar B$, $\bar A$ 与 $B$,  $\bar A$ 与 $\bar B$

--------------------------------------------------------------------------------
# 2. 随机变量及其分布
* **定义**: 设随机试验的样本空间为 $S=\{e\}$. $X = X(e)$ 是定义在样本空间 $S$ 上的实值单值函数, 称 $X(e)$ 为**随机变量**

## 2.1. 离散型随机变量及其分布
* **(0-1)分布**
    * 随机变量只有 0 和 1 两个值, 概率分别是 $1-p, p$
* **二项分布**
    * 设试验 $E$ 只有两个可能的结果: $A$ 和 $\bar A$, 则称 $E$ 为**伯努利 (Bernoulli) 试验**, 设 $P(A) = p (0< p < 1)$, 此时 $P(\bar A) = 1-p$. 将 $E$ 独立重复 $n$ 次, 则称这一串重复的独立试验为 $n$ 重伯努利试验, 则 $$P\{X=k\} = {n \choose k} p^k (1-p)^{n-k}, \quad k = 1,2,\cdots,n$$
* **泊松 (Poisson) 分布**
    * 设随机变量 $X$ 所有的可能的值为 $0,1,2,\cdots$, 而取各个值的概率为 $$P\{X=k\} = \dfrac{\lambda ^k e^{-\lambda}}{k !}, k=0,1,2,\cdots,n$$ 其中 $\lambda > 0$ 是常数, 则称 $X$ 服从参数为 $\lambda$ 的泊松分布, 记为 $X \sim \pi(\lambda)$
    * **泊松定理**: 设 $\lambda > 0$ 是一个常数, $n$ 是任意正整数, 设 $np_n = \lambda$, 则对于任一固定的非负整数 $k$, 有
        $$\begin{aligned} \lim \limits_{n \to \infin}  {n \choose k} p_n^k (1-p_n)^{n-k} &= \lim \limits_{n \to \infin} \dfrac{n(n-1)\cdots(n-k+1)}{k!}(\dfrac{\lambda}{n})^k(1-\dfrac{\lambda}{n})^n (1-\dfrac{\lambda}{n})^{-k}
            \\ &= \lim \limits_{n \to \infin} \dfrac{\lambda^k}{k!} (1+\dfrac{-\lambda}{n})^n \dfrac{n(n-1)\cdots(n-k+1)}{n^k} (1-\dfrac{\lambda}{n})^{-k}
            \\ &= \dfrac{\lambda ^k e^{-\lambda}}{k !} \end{aligned}$$
    ![泊松分布](/assets/概率与统计-泊松分布.jpg)

## 2.2. 连续型随机变量及其分布
* **定义**: 如果对于随机变量 $X$ 的分布函数 $F(x)$, 存在分布可积函数 $f(x)$, 使对于任意实数 $x$ 有 $$F(x) = \displaystyle \int _{-\infin} ^\infin f(t) \mathrm{d} t$$ 则称 $X$ 为连续型随机变量, $f(x)$ 称为 $X$ 的**概率密度函数**, 简称**概率密度**
* **性质**:
    1. $f(x) \geqslant 0$
    1. $\displaystyle \int _{-\infin}^{\infin} f(x) \mathrm{d}x = 1$
    1. 对于任意实数 $x_1, x_2 (x_1 \leqslant x_2)$, $$P\{x_1 < X \leqslant x_2\} = F(x_2) - F(x_1) = \displaystyle \int _{x_1}^{x_2} f(x) \mathrm{d}x$$
    1. 若 $f(x)$ 在点 $x$ 处连续, 则 $F'(x) = f(x)$
* **均匀分布**
    * 若连续随机变量具有概率密度函数 $f(x) = \begin{cases} \dfrac{1}{b-a} &, a < x < b \\ 0 &, others \end{cases}$, 则称其在区间 $(a,b)$ 上服从均匀分布, 记为 $X \sim U(a,b)$
* **指数分布**
    * 若连续随机变量具有概率密度函数 $f(x) = \begin{cases} \dfrac{1}{\theta} \mathrm{e}^{-x/\theta} &, x > 0 \\ 0 &, others \end{cases}$, 则称其服从参数为 $\theta$ 的指数分布
* **正态分布/高斯(Guass)分布**
    * 若连续随机变量具有概率密度函数 $f(x) = \dfrac{1}{\sqrt{2\pi} \sigma} \large \mathrm{e} ^{-\frac{(x-\mu)^2}{2 \sigma ^2}}$, 其中 $\mu, \sigma (\sigma > 0)$ 为常数, 则称其服从参数为 $\mu, \sigma$ 的正态分布, 记为 $X \sim N(\mu, \sigma^2)$
        * 曲线关于 $x=\mu$ 对称
        * 当 $x=\mu$ 时取得最大值 $f(\mu) = \dfrac{1}{\sqrt{2\pi} \sigma}$
        * 当 $\mu = 0, \sigma = 1$ 时称为**标准正态分布**, 其概率密度为 $\varphi(x) = \dfrac{1}{\sqrt{2\pi}} \large \mathrm{e} ^{-t^2/2}$, 分布函数为 $\displaystyle \Phi(x) = \dfrac{1}{\sqrt{2\pi}} \int _{-\infin}^{x} \mathrm{e} ^{-t^2/2} \mathrm{d}t$
            > $P\{\mu -  \sigma < X < \mu +  \sigma\} = \Phi(1) - \Phi(-1) = 68.26 \%$
            > $P\{\mu - 2\sigma < X < \mu + 2\sigma\} = \Phi(2) - \Phi(-2) = 95.44 \%$
            > $P\{\mu - 3\sigma < X < \mu + 3\sigma\} = \Phi(3) - \Phi(-3) = 99.74 \%$
    * **引理**: 若 $X \sim N(\mu, \sigma^2)$, 则 $Z = \dfrac{X-\mu}{\sigma} \sim N(0,1)$
    * **分位点**: 设 $X \sim N(0,1)$, 若 $z_\alpha$ 满足条件 $P\{X > z_\alpha\} = \alpha, \ 0 < \alpha < 1$, 则称点 $z_\alpha$ 为标准正态分布的 **上 $\alpha$ 分位点**
        * $z_{1-\alpha} = - z_\alpha$

## 2.3. 二维随机变量, $n$ 维随机变量
* **定义**: 设 $(X, Y)$ 是二维随机变量, 对于任意实数 $x, y$, 二元函数 $$F(x, y) = P\{(X \leqslant x) \cap (Y \leqslant y)\} \xlongequal{记作} P\{X \leqslant x, Y \leqslant y\}$$ 称为二维随机变量 $(X, Y)$ 的**分布函数**, 或称为随机变量 $X$ 和 $Y$ 的**联合分布函数**
    * 离散型二维随机变量, 联合分布律
    * 连续型二维随机变量, 联合概率密度
* **性质**:
    1. $F(x, y)$ 是变量 $x$ 和 $y$ 的不减函数, 即对于任意固定的 $y$, 当 $x_2 > x_1$ 时, $F(x_2, y) \geqslant F(x_1, y)$; 对于任意固定的 $x$, 当 $y_2 > y_1$ 时, $F(x, y_2) \geqslant F(x, y_1)$
    1. $0 \leqslant F(x,y) \leqslant 1$, 且
        * 对于任意固定的 $y$, $F(-\infin, y) = 0$,
        * 对于任意固定的 $x$, $F(x, -\infin) = 0$,
        * $F(-\infin, -\infin) = 0$
        * $F(\infin, \infin) = 1$
    1. $F(x+0, y) = F(x, y), F(x, y+0) = F(x, y)$, 即 $F(x, y)$ 关于 $x$ 右连续, 关于 $y$ 也右连续
    1. 对于任意 $(x_1, y_1), (x_2, y_2), x_1 < x_2, y_1 < y_2$, 下列不等式成立: $F(x_2, y_2) - F(x_2, y_1)+ F(x_1, y_1) - F(x_1, y_2) \geqslant 0$
* 联合概率密度的**性质**
    1. $f(x, y) \geqslant 0$
    1. $\displaystyle \int _{-\infin}^{\infin} \int _{-\infin}^{\infin} f(x,y) \mathrm{d}x \mathrm{d}y = F(\infin, \infin) = 1$
    1. 设 $G$ 是$xOy$ 平面上的区域, 点 $(X, Y)$ 落在 $G$ 内的概率为 $P\{(X, Y) \in G\} = \displaystyle \iint _G f(x, y) \mathrm{d} x \mathrm{d} y$
    1. 若 $f(x, y)$ 在点 $(x, y)$ 连续, 则有 $\dfrac{\partial ^2 F(x, y)}{\partial x \partial y} = f(x, y)$
    </br>
* 二维正态分布, 记 $(X,Y) \sim N(\mu_1, \mu_2, \sigma _1^2, \sigma _2^2, \rho)$
    $$f(x,y) = \displaystyle \dfrac{1}{2\pi \sigma _1 \sigma _2 \sqrt{1-\rho^2}} \exp \Big\{\dfrac{-1}{2(1-\rho^2)}\Big[ \dfrac{(x-\mu_1)^2}{\sigma_1^2} - 2\rho \dfrac{(x-\mu_1)(x-\mu_2)}{\sigma_1 \sigma_2} + \dfrac{(x-\mu_2)^2}{\sigma_2}\Big] \Big\}$$ 其中: $\mu_1, \mu_2$ 分别是 $X,Y$ 的平均值, $\sigma_1, \sigma_2$ 分别是 $X,Y$ 的标准差, $\rho$ 是 $(X,Y)$ 的相关系数

## 2.4. 边缘分布
* **定义**: 二维随机变量 $(X, Y)$ 作为一个整体, 具有分布函数 $F(X, Y)$, 而 $X$ 和 $Y$ 都是随机变量, 各自有各自的分布函数, 将它们分别记作 $F_X(x), F_Y(y)$, 依次称为二维随机变量 $(X, Y)$ 关于 $X$ 和关于 $Y$ 的**边缘分布函数**. $$F_X(x) = P\{X \leqslant x\} = P\{X \leqslant x, Y < \infin\} = F(x, \infin) \\ F_Y(y) = F(\infin, y)$$
    * 离散型随机变量的**边缘分布律**: $$\displaystyle \begin{aligned} P\{X = x_i\} = \sum _{j=1}^{\infin} p _{ij}, \quad & i = 1, 2, \cdots \\ P\{Y = y_j\} = \sum _{i=1}^{\infin} p _{ij}, \quad & j = 1, 2, \cdots \end{aligned}$$ 记 $$\displaystyle p _{i\cdot} = \sum _{j=1}^{\infin} p _{ij} = P\{X = x_i\}, i = 1, 2, \cdots \\ p _{\cdot j} = \sum _{i=1}^{\infin} p _{ij} = P\{Y = y_j\}, j = 1, 2, \cdots$$ 分别称 $p _{i\cdot}, p _{\cdot j}$ 为 $(X, Y)$ 关于$X$ 和 $Y$ 的边缘分布律
    * 连续型随机变量的**边缘概率密度**: $$\begin{aligned} f_X(x) &= \displaystyle \int _{-\infin}^{\infin} f(x, y) \mathrm{d} y, \\ f_Y(y) &= \int _{-\infin}^{\infin} f(x, y) \mathrm{d} x \end{aligned}$$

## 2.5. 条件分布
* **定义**: 设 $(X, Y)$ 是二维离散型随机变量, 对于固定的 $j$, 若 $P\{Y=y_j\} > 0$, 则称 $$P\{X=x_i | Y = y_j\} = \dfrac{P\{X=x_i, Y = y_j\}}{P\{Y=y_j\}} = \dfrac{p _{ij}}{p _{\cdot j}}, i = 1, 2, \cdots$$ 为在 $Y=y_j$ 条件下 $X$ 的**条件分布律**, 相对的, 称 $P \{Y=y_j | X = x_i\}$ 为在 $X=x_i$ 条件下 $Y$ 的**条件分布律**
* **定义**: 设二维随机变量 $(X,Y)$ 的概率密度为 $f(x,y)$, $(X,Y)$ 关于 $Y$ 的边缘概率密度为 $f_Y(y)$, 若对于固定 $y$, $f_Y(y) > 0$, 则称 $\dfrac{f(x,y)}{f_Y(y)}$ 为在 $Y = y$ 条件下 $X$ 的**条件概率密度**, 记作 $f_{X|Y} (x|y) = \dfrac{f(x,y)}{f_Y(y)}$, 称 $\displaystyle \int _{-\infin}^{x} f _{X|Y}(x,y) = \int _{-\infin}^x \dfrac{f(x,y)}{f_Y(y)}\mathrm{d}x$ 为在 $Y = y$ 条件下 $X$ 的条件分布函数， 记作 $P\{X \leqslant x | Y =y\}$ 或 $F_{X|Y}(x|y)$, 即 $$F_{X|Y}(x|y) = P\{X \leqslant x | Y =y\} = \int _{-\infin}^x \dfrac{f(x,y)}{f_Y(y)}\mathrm{d}x$$ 类似地, 可以定义 $f_{Y|X}(y|x) = \dfrac{f(x,y)}{f_X(x)}$ 和 $F_{Y|X}(y|x) = \displaystyle \int _{-\infin}^y \dfrac{f(x,y)}{f_X(x)}\mathrm{d}y$

## 2.6. 相互独立的随机变量
* **定义**: 设 $F(x,y)$ 及 $F_X(x),F_Y(y)$ 分别是二维随机变量 $(X,Y)$ 的分布函数即边缘分布函数, 若对于所有的 $x, y$ 有 $P\{X \leqslant x, Y \leqslant y\} = P\{X \leqslant x\} P\{Y \leqslant y\}$, 即 $$F(x,y) = F_X(x) F_Y(y)$$ 即称随机变量 $X$ 和 $Y$ 是**相互独立**的
    * 连续型随机变量相互独立: $f(x,y) = f_X(x) f_Y(y)$
    * 离散型随机变量相互独立: $P\{X=x_i, Y=y_j\} = P\{X=x_i\} P\{Y=y_j\}$
* **定理**: 设 $(X_1, X_2, \cdots, X_m)$ 和 $(Y_1, Y_2, \cdots, Y_n)$ 相互独立, 则 $X_i(i = 1,2,\cdots, m)$ 和 $Y_j(j=1,2,\cdots,n)$ 相互独立, 又若 $h, g$ 是连续函数, 则 $h(X_1, X_2, \cdots, X_m)$ 和 $(Y_1, Y_2, \cdots, Y_n)$ 相互独立

## 2.7. 两个随机变量的函数的分布
1. $Z = X+Y$ 的分布函数
    * 设 $(X,Y)$ 是二维连续型随机变量, 它具有概率密度 $f(x,y)$, 则 $Z = X+Y$ 仍然为连续型随机变量, 其概率密度为 $$f_{X+Y}(z) = \displaystyle \int _{-\infin}^{\infin} f(z-y,y)\mathrm{d}y \quad 或 \quad f _{X+Y}(z) = \displaystyle \int _{-\infin}^{\infin} f(x,z-x)\mathrm{d}x$$
    * 又若 $X$ 和 $Y$ 相互独立, 设 $(X,Y)$ 关于 $X,Y$ 的边缘密度分别为 $f_X(x), f_Y(y)$, 则 $$f_{X+Y}(z) = \displaystyle \int _{-\infin}^{\infin} f_X(z-y)f_Y(y)\mathrm{d}y \quad 或 \quad f _{X+Y}(z) = \displaystyle \int _{-\infin}^{\infin} f_X(x)f_Y(z-x)\mathrm{d}x$$ 这两个公式被称为卷积公式, 记为 $f_X * f_Y$, 即 $$f_X * f_Y = \displaystyle \int _{-\infin}^{\infin} f_X(z-y)f_Y(y)\mathrm{d}y = \int _{-\infin}^{\infin}f_X(x)f_Y(z-x)\mathrm{d}x$$
    * 有限个相互独立的正态随机变量的线性组合仍然服从正态分布
1. $Z=\dfrac{Y}{X}$ 和 $Z=XY$ 的分布
    * 设 $(X,Y)$ 是二维连续随机变量, 它具有概率密度 $f(x,y)$, 则 $Z=\dfrac{Y}{X}, Z=XY$ 仍然为连续型随机变量, 其概率密度为 $$f_{Y/X}(z) = \displaystyle \int _{-\infin}^{\infin} |x| f(x,xz) \mathrm{d} x$$ $$f _{XY}(z) = \displaystyle \int _{-\infin}^{\infin} \dfrac{1}{|x|} f(x, \dfrac{z}{x}) \mathrm{d} x$$
    * 又若 $X$ 和 $Y$ 相互独立, 设 $(X,Y)$ 关于 $X, Y$ 的边缘密度分别为 $f_X(x), f_Y(y)$, 则 $$f_{Y/X}(x) = \displaystyle \int _{-\infin}^{\infin} |x| f_X(x) f_Y(xz) \mathrm{d} x$$ $$f_{XY}(x) = \displaystyle \int _{-\infin}^{\infin} \dfrac{1}{|x|} f_X(x) f_Y(\dfrac{z}{x}) \mathrm{d} x$$
1. $M=\max \{X,Y\}$ 及 $M=\min\{X,Y\}$ 的分布
    * 设 $X_1, X_2, \cdots, X_n$ 是 $n$ 个相互独立的随机变量, 它们的分布函数分别为 $F_{X_i}(x_i) \ (i=1,2,\cdots, n)$, 则 $M=\max\{X_1, X_2, \cdots, X_n\}$ 及 $N = \min \{X_1, X_2, \cdots, X_n\}$ 的分布函数分别为 $$F_{\max}(z) = F_{X_1}(z) F_{X_2}(z)\cdots F_{X_n}(z)$$ $$F_{\min}(z) = 1- \Big[1-F_{X_1}(z)\Big] \Big[1-F_{X_2}(z)\Big]\cdots \Big[1-F_{X_n}(z)\Big]$$ 特别, 当 $X_1, X_2, \cdots, X_n$ 相互独立且具有相同分布函数 $F(x)$ 时 $$F_{\max}(z) = \Big[F_{X}(z)\Big]^n$$ $$F_{\min}(z) = 1- \Big[1-F_{X}(z)\Big]^n$$

--------------------------------------------------------------------------------
# 3. 随机变量的数学特征
## 3.1. 数学期望
* **定义**: 设离散型随机变量 $X$ 的分布律为 $P\{X=x_k\} = p_k, (k=1,2,\cdots)$, 若级数 $\displaystyle \sum _{k=1}^{\infin} x_k p_k$ 绝对收敛, 则称其为随机变量 $X$ 的**数学期望**, 记为 $E(X)$, 即 $$E(X) = \displaystyle \sum _{k=1}^{\infin} x_k p_k$$
* **定义**: 设连续型随机变量 $X$ 的概率密度为 $f(x)$, 若积分 $\displaystyle \int _{-\infin}^{\infin} x f(x) \mathrm{d} x$ 绝对收敛, 则称其为随机变量 $X$ 的**数学期望**, 记为 $E(X)$, 即 $$E(X) = \displaystyle \int _{-\infin}^{\infin} x f(x) \mathrm{d} x$$
* **数学期望**简称**期望**, 又称为**均值**
* **性质**:
    1. 设 $C$ 是常数, 则 $E(C) = C$
    1. 设 $X$ 是一个随机变量, 则 $E(CX) = CE(X)$
    1. 设 $X,Y$ 是两个随机变量, 则 $E(X+Y) = E(X) + E(Y)$
    1. 设 $X,Y$ 是两个相互独立的随机变量, 则 $E(XY) = E(X) E(Y)$

## 3.2. 方差
* **定义**: 设 $X$ 是一个随机变量, 若 $E\{[X-E(X)]^2\}$ 存在, 则称其为 $X$ 的**方差**, 记为 $D(X)$ 或 $Var(X)$, 即 $$D(X) = Var(X) = E\{\Big[X-E(X)\Big]^2\} = E(X^2) - \Big[E(X)\Big]^2$$
* **标准差** 或 **均方差**: $\sigma (X) = \sqrt{D(X)}$
* **标准化变量**: $X^* = \dfrac{X-\mu}{\sigma}$, 其中 $\mu = E(X), \sigma = \sqrt{D(X)}$, $X^*$ 的期望为 0, 方差为 1
* **性质**:
    1. 设 $C$ 是常数, 则 $D(C) = C$
    1. 设 $X$ 是一个随机变量, 则 $D(CX) = C^2 D(X), D(X+C) = D(X)$
    1. 设 $X,Y$ 是两个随机变量, 则 $D(X+Y) = D(X) + D(Y)$
    1. $D(X)=0$ 的充要条件是 $X$ 以概率 1 取常数 $E(X)$, 即 $P\{X=E(X)\} = 1$
* **定理**: 设随机变量 $X$ 具有数学期望 $E(X) = \mu$, 方差 $D(X) = \sigma ^2$, 则对于任意正数 $\varepsilon$, 不等式 $$P\{|x-\mu|\geqslant \varepsilon\} \leqslant \dfrac{\sigma ^2}{\varepsilon^2}$$ 成立, 称其为**切比雪夫(Chebyshev)不等式**

## 3.3. 常见分布的期望和方差
分布      | 参数 | 分布律或概率密度 | 期望 | 方差
:-------: | :--: | :---------------:| :--: | :--:
(0,1)分布 | - | - | $p$ | $p(1-p)$
二项分布  | $X \sim b(n, p)$ | $P\{X=k\} = C^k_n p^k (1-p)^{n-k},$ </br> $k = 1, 2, \cdots, n$ | $np$ | $np(1-p)$
泊松分布  | $X \sim \pi(\lambda)$ | $P\{X=k\} = \dfrac{\lambda ^k e^{-\lambda}}{k !},$ </br> $k=0, 1, 2, \cdots, n$ | $\lambda$ | $\lambda$
均匀分布  | $X \sim U(a,b)$ | $f(x) = \begin{cases} \dfrac{1}{b-a}, & a < x < b \\ 0, & others \end{cases}$ | $\dfrac{a+b}{2}$ | $\dfrac{(b-a)^2}{12}$
高斯分布  | $X \sim N(\mu,\sigma^2)$ | $f(x) = \dfrac{1}{\sqrt{2\pi} \sigma} \large \mathrm{e} ^{-\frac{(x-\mu)^2}{2 \sigma ^2}}$ | $\mu$ | $\sigma^2$
指数分布  | - | $f(x) \begin{cases} \dfrac{1}{\theta} \mathrm{e}^{-x/\theta}, & x > 0 \\ 0, & x \leqslant 0 \end{cases}$ | $\theta$ | $\theta^2$

## 3.4. 协方差与相关系数
* **协方差**: 记为 $\mathrm{Cov}(X,Y)$, 即 $$\mathrm{Cov}(X,Y) = E\{[X-E(X)][Y-E(Y)]\}$$
* **相关系数**: $$\rho _{XY} = \dfrac{\mathrm{Cov}(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}$$
    * $\rho _{XY} = 0$ 时, 称 $X,Y$ **不相关**
* **性质**:
    1. $\mathrm{Cov} (aX, bY) = ab\mathrm{Cov}(X,Y)$, $a,b$ 是常数
    1. $\mathrm{Cov} (X_1 + X_2, Y) = \mathrm{Cov}(X_1,Y) + \mathrm{Cov}(X_2,Y)$
* **定理**:
    1. $|\rho _{XY}| \leqslant 1$
    1. $|\rho _{XY}| = 1$ 的充要条件是存在常数 $a,b$, 使 $P\{Y=a+bX\} = 1$

## 3.5. 矩, 协方差矩阵
* **定义**: 设 $X,Y$ 是随机变量,
    * 若 $E(X^k),\quad k = 1,2,\cdots$ 存在, 称它为 $X$ 的 **$k$ 阶原点矩**, 简称 **$k$阶矩**
    * 若 $E\{[X-E(X)]^k\},\quad k=1,2,\cdots$ 存在, 称它为 $X$ 的  **$k$ 阶中心矩**,
    * 若 $E(X^kY^l),\quad k,l = 1,2,\cdots$ 存在, 称它为 $X,Y$ 的 **$k+l$ 阶混合矩**
    * 若 $E\{[X-E(X)]^k[Y-E(Y)]^l\},\quad k,l = 1,2,\cdots$ 存在, 称它为 $X,Y$ 的  **$k+l$ 阶混合中心矩**,
* **定义**: 二维随机变量 $(X_1,X_2)$ 有4个二阶中心矩, 分别记作 $$\begin{aligned}
        c_{11} &= E\{[X_1 - E(X_1)]^2\} \\
        c_{12} &= E\{[X_1 - E(X_1)][X_2 - E(X_2)]\} \\
        c_{21} &= E\{[X_2 - E(X_2)][X_1 - E(X_1)]\} \\
        c_{22} &= E\{[X_2 - E(X_2)]^2\} \end{aligned}$$, 它们形成的矩阵 $\begin{bmatrix} c_{11} & c_{12} \\ c_{21} & c_{22}\end{bmatrix}$ 称为**协方差矩阵**
    $n$ 维随机变量 $(X_1, X_2, \cdots, X_n)$ 的 **协方差矩阵**为 $$\bm C = \begin{bmatrix}
        c_{11} & c_{12} &\cdots & c_{1n} \\
        c_{21} & c_{22} &\cdots & c_{2n} \\
        \vdots & \vdots &       & \vdots \\
        c_{n1} & c_{n2} &\cdots & c_{nn} \end{bmatrix}$$ 其中 $c_{ij} = \mathrm{Cov}(X_i, X_j) = E\Big\{\Big[X_i-E(X_i)\Big]\Big[X_j - E(X_j)\Big]\Big\}$
    > 由于 $c_{ij} = c_{ji}$, 因此协方差矩阵是一个对称矩阵
* $n$ 维正态随机变量 $(X_1, X_2, \cdots, X_n)$ 的概率密度为 $$f(x_1, x_2, \cdots, x_n) = \dfrac{1}{(2\pi)^{n/2}(\det \bm C)^{1/2}} \mathrm {exp} \Big \{ -\dfrac{1}{2}(\bm X- \bm \mu)^T \bm C^{-1}(\bm X - \bm \mu)\Big\}$$ 其中 $\bm X = \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}, \bm \mu = \begin{pmatrix} \mu_1 \\ \mu_2 \\ \vdots \\ \mu_n \end{pmatrix}$
    * 性质:
        1. $n$ 维正态随机变量 $(X_1, X_2, \cdots, X_n)$ 的每个分量 $X_i$ 都是正态随机变量; 反之, 若 $X_1, X_2, \cdots, X_n$ 都是正态随机变量, 且相互独立, 则 $(X_1, X_2, \cdots, X_n)$ 是 $n$ 维正态随机变量
        1. $n$ 维随机变量 $(X_1, X_2, \cdots, X_n)$ 服从 $n$ 维正态随机分布 $\iff$ $X_1, X_2, \cdots, X_n$ 的任意线性组合 $l_1 X_1 + l_2 X_2 + \cdots + l_n X_n, \ (l_1, l_2, \cdots, l_n 不全为零)$ 服从一维正态分布
        1. 若 $(X_1, X_2, \cdots, X_n)$ 服从 $n$ 维正态随机分布, 设 $Y_1, Y_2, \cdots, Y_k$ 是 $X_j$ 的线性函数, 则 $(Y_1, Y_2, \cdots, Y_k)$ 也服从多为正态分布
        1. 若 $(X_1, X_2, \cdots, X_n)$ 服从 $n$ 维正态随机分布, 则 "$X_1, X_2, \cdots, X_n$ 相互独立" $\iff$ "$X_1, X_2, \cdots, X_n$ 两两不相关"

## 3.6. 其它特征
* 最大数, 最小数, 极差, 中位数, 众数

--------------------------------------------------------------------------------
# 4. 大数定律及中心极限定理

## 4.1. 大数定律
> 算术平均值依概率收敛于数学期望
* **弱大数定理(辛钦大数定理)**: 设 $X_1,X_2,\cdots$ 是相互独立、服从同一分布的随机变量序列, 且具有数学期望 $E(X_k) = \mu \ (k = 1,2,\cdots)$, 作前 $n$ 个变量的算术平均 $\displaystyle \frac 1 n \sum _{k=1}^n X_k$, 则对于任意 $\varepsilon > 0$, 有 $$\lim _{n\to \infin} P \Big\{\Big|\dfrac{1}{n}\sum _{k=1}^n X_k - \mu \Big| < \varepsilon\Big\} = 1$$
* **弱大数定理(辛钦大数定理)**: 设 $X_1,X_2,\cdots$ 是相互独立、服从同一分布的随机变量序列, 且具有数学期望 $E(X_k) = \mu \ (k = 1,2,\cdots)$, 则序列 $\bar X = \dfrac{1}{n} \displaystyle \sum _{k=1}^n X_k$ 依概率收敛于 $\mu$, 即 $\bar X\xrightarrow{P} \mu$
* **伯努利大数定理**: 设 $f_A$ 是 $n$ 次独立重复试验中时间 $A$ 发生的次数, $p$ 是时间 $A$ 在每次试验中发生的概率, 则对于任意 $\varepsilon > 0$, 有 $$\lim _{n \to \infin} P\Big\{\Big| \dfrac{f_A}{n} - p\ \Big| < \varepsilon \Big\} = 1 \ or \ \lim _{n \to \infin} P\Big\{\Big| \dfrac{f_A}{n} - p\ \Big| \geqslant \varepsilon\Big\} = 0$$

## 4.2. 中心极限定理
> 大量随机变量之和的分布逼近于正态分布
* **独立同分布的中心极限定理**: 设随机变量 $X_1, X_2,\cdots$ 相互独立, 服从同一分布, 且具有数学期望和方差: $E(X_k) = \mu, D(X_k) = \sigma ^2 > 0 \quad (k =1,2,\cdots)$, 则随机变量之和 $\displaystyle \sum _{k=1}^n X_k$ 的标准化变量 $$Y_n = \dfrac{\displaystyle \sum _{k=1}^n X_k - E(\displaystyle \sum _{k=1}^n X_k)}{\sqrt {D(\displaystyle \sum _{k=1}^n X_k)}} = \dfrac{\displaystyle \sum _{k=1}^n X_k - n\mu}{\sqrt n \sigma}$$ 的分布函数 $F_n(X)$ 对于任意 $x$ 满足 $$\lim _{n \to \infin} F_n(x) = \lim _{n \to \infin} P \Bigg \{\dfrac{\displaystyle \sum _{k=1}^n X_k - n \mu}{\sqrt n \sigma} \leqslant x \Bigg\} = \int _{-\infin}^x \dfrac{1}{\sqrt{2\pi}}\mathrm{e} ^ {-t^2/2} \mathrm{d} t = \Phi(x)$$
    * 即当 $n$ 充分大时, $\dfrac{\bar X - \mu}{\sigma / \sqrt n} \overset{近似地}{\huge \sim} N(0,1)$ 或 $\bar X \overset{近似地}{\huge \sim} N(\mu, \sigma^2/n)$
* **李雅普诺夫(Lyapunov)定理**: 设随机变量 $X_1, X_2,\cdots$ 相互独立, 服从同一分布, 且具有数学期望和方差: $E(X_k) = \mu _k, D(X_k) = \sigma _k^2 > 0 \quad (k =1,2,\cdots)$, 记 $$B_n^2 = \displaystyle \sum _{k=1}^n \sigma_k^2$$ 若存在整数 $\delta$, 使得当 $n \to \infin$ 时, $$\dfrac{1}{B_n^{2+\delta}} \displaystyle \sum _{k=1}^n E\{|X_k - \mu _k|^{2+\delta}\} \to 0$$ 则随机变量之和 $\displaystyle \sum _{k=1}^n X_k$ 的标准化变量 $$Z_n = \dfrac{\displaystyle \sum _{k=1}^n X_k - E(\displaystyle \sum _{k=1}^n X_k)}{\sqrt {D(\displaystyle \sum _{k=1}^n X_k)}} = \dfrac{\displaystyle \sum _{k=1}^n X_k - \sum _{k=1}^n \mu_k}{B_n}$$ 的分布函数 $F_n(x)$ 对于任意 $x$, 满足 $$\lim _{n \to \infin} F_n(x) = \lim _{n \to \infin} P \Bigg \{\dfrac{\displaystyle \sum _{k=1}^n X_k - \sum _{k=1}^n \mu_k}{B_n} \leqslant x \Bigg\} = \int _{-\infin}^x \dfrac{1}{\sqrt{2\pi}}\mathrm{e} ^ {-t^2/2} \mathrm{d} t = \Phi(x)$$
    * 即当 $n$ 很大时, $Z_n = \dfrac{\displaystyle \sum _{k-1}^n X_k - \sum _{k=1}^n\mu_k}{B_n} \overset{近似地}{\huge \sim} N(0,1)$, $\displaystyle \sum _{k=1}^n X_k = B_n Z_n + \sum _{k=1}^n \mu_k \overset{近似地}{\huge \sim} N(\sum _{k=1}^n \mu_k, B_n^2)$
    * 无论各个随机变量服从什么分布, 只要满足定理的条件, 那么它们的和 $\displaystyle \sum _{k=1}^n X_k$ 当 $n$ 很大时, 就近似地服从正态分布
* **棣莫弗-拉普拉斯(De Moivre - Laplace)定理**: 设随机变量 $\eta _n (n = 1,2,\cdots)$ 服从参数为 $n, p(0 < p < 1)$ 的二项分布, 则对于任意 $x$, 有 $$\lim _{n \to \infin} P \Big\{ \dfrac{\eta_n - np}{\sqrt{np(1-p)}} \leqslant x \Big\} = \int _{-\infin}^x \dfrac{1}{\sqrt{2\pi}}\mathrm{e} ^ {-t^2/2} \mathrm{d} t = \Phi(x)$$
    * 即: 正态分布是二项分布的极限分布

--------------------------------------------------------------------------------
# 5. 样本及抽样分布
## 5.1. 随机样本
* **概念**: 总体, 容量, 有限总体, 无限总体
* **定义**: 设 $X$ 是具有分布函数 $F$ 的随机变量, 若 $X_1,X_2,\cdots,X_n$ 是具有同一分布函数 $F$ 的、相互独立的随机变量， 则称 $X_1,X_2,\cdots,X_n$ 为从分布函数 $F$ (或总体 $F$, 或总体 $X$) 得到的容量为 $n$ 的简单**随机样本**, 简称**样本**, 它们的观察值 $x_1, x_2, \cdots, x_n$ 称为**样本值**, 又称为 $X$ 的 $n$ 个**独立的观察值**
    * 由定义得: $X_1,X_2,\cdots,X_n$ 的分布函数为 $$F^* (x_1,x_2,\cdots,x_n) = \displaystyle \prod _{i=1}^n F(x_i)$$ 若 $X$ 具有概率密度 $f$, 则 $X_1,X_2,\cdots,X_n$ 的概率密度为 $$f^* (x_1,x_2,\cdots,x_n) = \displaystyle \prod _{i=1}^n f(x_i)$$

## 5.2. 抽样分布
* 设 $X_1,X_2,\cdots,X_n$  是来自总体 $X$ 的一个样本, 则
    * 样本平均值: $\bar X = \dfrac{1}{n} \displaystyle \sum _{i=1}^n X_i$
    * 样本方差: $S^2 = \dfrac{1}{n-1} \displaystyle \sum _{i=1}^n (X_i - \bar X)^2 = \dfrac{1}{n-1} (\sum _{i=1}^n X_i^2 - n {\bar X}^2)$
        > 分母不是 $n$ 是为了对自由度进行修正, 这叫贝塞尔校正 (Bessel's Correction). 因为 $\bar X$ 对数据独立性造成了干扰
    * 样本标准差: $S = \sqrt {S^2} = \sqrt {\dfrac{1}{n-1} \displaystyle \sum _{i=1}^n (X_i - \bar X)^2}$

### 5.2.1. $\chi^2$ 分布 (卡方分布)
* **定义**: 设 $X_1,X_2,\cdots,X_n$ 是来自总体 $N(0,1)$ 的样本, 则称统计量 $$\chi^2 = X_1^2 + X_2^2 + \cdots + X_n^2$$ 服从自由度为 $n$ 的 $\chi^2$ 分布, 记作 $\chi^2 \sim \chi^2(n)$
* $\chi^2(n)$ 分布的概率密度为 $$f(y) = \begin{cases} \dfrac{1}{2^{n/2}\Gamma(n/2)} y^{n/2-1} \mathrm{e} ^{-y/2} &, y>0 \\ 0 &, others \end{cases}$$
    > Gamma 函数 - $\Gamma(x)$, 本质是阶乘函数在实数与复数上扩展的一类函数 $$\Gamma(x) = \displaystyle \int _0^\infin t^{x-1}\mathrm{e}^{-t} \mathrm{d}t, (x>0)$$
    > 性质1: $\Gamma(x+1) = x\Gamma(x)$
* **性质：**
    1. 可加性: $\chi^2(n_1) + \chi^2(n_2) \sim \chi^2(n_1 + n_2)$
    1. $E(\chi^2) = n, D(\chi^2)=2n$
* 分位点:
    * 当 $n$ 充分大时, $\chi_\alpha^2(n) \approx \dfrac{1}{2}(z_\alpha + \sqrt {2n-1})^2$
![卡方分布](/assets/概率与统计-卡方分布.png)

### 5.2.2. $t$ 分布
* 定义: 设 $X \sim N(0,1), Y \sim \chi^2(n)$, 且$X,Y$ 相互独立, 则称随机变量 $$t=\dfrac{X}{\sqrt{Y/n}}$$ 服从自由度为 $n$ 的 $t$ 分布 (Student 分布), 记作 $t\sim t(n)$
* $t$ 分布的概率密度为 $$h(t) = \dfrac{\Gamma[(n+1)/2]}{\sqrt{\pi n}\Gamma(n/2)}\Big(1+\dfrac{t^2}{n}\Big)^{-(n+1)/2}, (-\infin < t < \infin)$$
* $\displaystyle \lim _{ n\to \infin} h(t) = \dfrac{1}{\sqrt{2\pi}}\mathrm{e}^{-t^2/2}$
    * 当 $n$ 足够大时 $t$ 分布近似于 $N(0,1)$ 分布, 但较小时相差较大
* 分位点:
    * $t_{1-\alpha}(n) = -t_\alpha(n)$
    * 当 $n$ 很大时 $t_\alpha(n) \approx z_\alpha$
![t分布](/assets/概率与统计-t分布.gif)

### 5.2.3. $F$ 分布
* **定义**: 设 $U\sim \chi^2(n_1), V\sim \chi^2(n_2)$, 且$U,V$ 相互独立, 则称随机变量 $$F=\dfrac{U/n_1}{V/n_2}$$ 服从自由度为 $(n_1, n_2)$ 的 $F$ 分布, 记作 $F\sim F(n_1, n_2)$
* $F$ 分布的概率密度为 $$\psi(y) = \begin{cases} \dfrac{\Gamma[(n_1+n_2)/2](n_1/n_2)^{n_1/2}y^{n_1/2-1}}{\Gamma(n_1/2)\Gamma(n_2/2)[1+(n_1y/n2)]^{(n_1+n_2)/2}} &, y > 0 \\ 0 &, others \end{cases}$$
* $\dfrac{1}{F} \sim F(n_2, n_1)$
* 分位点
    * $F_{1-\alpha}(n_1, n_2) = \dfrac 1 {F_\alpha(n_2, n_1)}$

### 5.2.4. 正态总体的样本均值与样本方差的分布
* **定理**
    1. 设 $X_1,X_2,\cdots,X_n$ 是来自正态总体 $N(\mu,\sigma^2)$ 的样本, $\bar X$ 是样本均值, 则有 $$\bar X \sim N(\mu, \dfrac{\sigma^2} n)$$
    1. 设 $X_1,X_2,\cdots,X_n$ 是来自正态总体 $N(\mu,\sigma^2)$ 的样本, $\bar X$ 和 $S^2$ 分别是样本均值和样本方差, 则有
        * $\dfrac{(n-1)S^2}{\sigma^2}\sim \chi^2(n-1)$
        * $\bar X$ 和 $S^2$ 相互独立
    1. 设 $X_1,X_2,\cdots,X_n$ 是来自正态总体 $N(\mu,\sigma^2)$ 的样本, $\bar X$ 和 $S^2$ 分别是样本均值和样本方差, 则有 $$\dfrac{\bar X - \mu}{S/\sqrt{n}} \sim t(n-1)$$
    1. 设 $X_1,X_2,\cdots,X_{n_1}$ 与 $Y_1,Y_2,\cdots,Y_{n_2}$ 分别是来自正态总体 $N(\mu_1,\sigma_1^2)$ 和 $N(\mu_2,\sigma_2^2)$ 的样本, 且两个样本相互独立, 设 $\bar X$ 和 $\bar Y$ 分别是两个样本的样本均值, $S_1^2$ 和 $S_2^2$ 分别是两个样本的样本方差, 则有
        * $\dfrac{S_1^2 / S_2^2}{\sigma_1^2/\sigma_2^2} \sim F(n_1-1, n_2-1)$
        * 当 $\sigma_1^2 = \sigma_2^2 =\sigma^2$ 时 $$\dfrac{(\bar X-\bar Y)-(\mu_1-\mu_2)}{S_\omega\sqrt{\dfrac{1}{n_1} + \dfrac{1}{n_2}}} \sim t(n_1+n_2-2)$$ 其中 $S_\omega^2 = \dfrac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1 + n_2 - 2}$

--------------------------------------------------------------------------------
# 6. 参数估计
## 6.1. 点估计
### 6.1.1. 矩估计法
* 设 $X$ 为连续型随机变量, 其概率密度为 $f(x;\theta_1, \theta_2, \cdots, \theta_k)$, 或 $X$ 为离散型随机变量, 其概率分布律为 $P\{X=x\} = p(x;\theta_1, \theta_2, \cdots, \theta_k)$, 其中 $\theta_1, \theta_2, \cdots, \theta_k$ 为待估参数, $X_1, X_2, \cdots, X_n$ 是来自 $X$ 的样本, 假设总体 $X$ 的前 $k$ 阶矩 $$\mu_l = E(X^l) = \displaystyle \int _{-\infin}^\infin x^l f(x; \theta_1, \theta_2, \cdots, \theta_k) \mathrm{d}x $$ 或 $$\mu_l = E(X^l) = \displaystyle \sum _{x \in \R _X} x^l p(x; \theta_1, \theta_2, \cdots, \theta_k)$$ $$(l=1,2,\cdots, k)$$ 存在, 一般来说, 它们是 $\theta_1, \theta_2, \cdots, \theta_k$ 的函数. 基于样本矩 $A_l = \dfrac 1 n \displaystyle \sum _{i=1}^n X_i^l$ 依概率收敛于相应的总体矩 $\mu_l$, 样本矩的连续函数依概率收敛于相应的总体矩的连续函数, 我们就用样本矩作为相应的总体矩的估计量, 而以样本矩的连续函数作为相应的总体矩的连续函数的估计量. 这种估计方法称为**矩估计法**
* 具体步骤:
    1. 设 $$\begin{cases} \mu_1 = \mu_1(\theta_1, \theta_2, \cdots, \theta_k) \\
                          \mu_2 = \mu_2(\theta_1, \theta_2, \cdots, \theta_k) \\
                          \cdots \\
                          \mu_k = \mu_k(\theta_1, \theta_2, \cdots, \theta_k)
        \end{cases}$$ 这是一个包含 $k$ 个未知参数的联立方程组, 从中解出 $\theta_1, \theta_2, \cdots, \theta_k$, 得到 $$\begin{cases}
            \theta_1 = \theta_1(\mu_1, \mu_2, \cdots, \mu_k) \\
            \theta_2 = \theta_2(\mu_1, \mu_2, \cdots, \mu_k) \\
            \cdots \\
            \theta_k = \theta_k(\mu_1, \mu_2, \cdots, \mu_k)
        \end{cases}$$
    1. 以 $A_i$ 代入 $\mu_i$, 就以 $$\hat \theta = \theta(A_1, A_2, \cdots, A_k)$$ 分布作为 $\theta_i$ 的估计量, 这种估计量称为 **矩估计量**, 矩估计量的观察值称为 **矩估计值**

### 6.1.2. 最大似然估计
* 若总体 $X$ 属离散型, 其分布律 $P\{X=x\} = p(x; \theta), \theta \in \Theta$ 的形式为已知, $\theta$ 为待估参数, $\Theta$ 是 $\theta$ 可能取值的范围, 设 $X_1, X_2, \cdots, X_n$ 是来自 $X$ 的样本, 则 $X_1, X_2, \cdots, X_n$ 的联合分布律为 $$\prod _{i=1}^n p(x;\theta)$$ 又设 $x_1, x_2, \cdots, x_n$ 是相应于样本 $X_1, X_2, \cdots, X_n$ 的一个样本值. 易知事件 $\{X_1 = x_1, X_2 = x_2, \cdots, X_n = x_n\}$ 的概率为 $$L(\theta) = L(x_1, x_2, \cdots, x_n; \theta) = \prod _{i=1}^n p(x;\theta), \theta \in \Theta$$ 它是 $\theta$ 的函数, 称为样本的 **似然函数**.
    固定样本观察值 $x_1, x_2, \cdots, x_n$ 在 $\theta$ 取值的可能范围内 $\Theta$ 内挑选使似然函数 $L(x_1, x_2, \cdots, x_n; \theta)$ 达到最大的参数值 $\hat \theta$, 作为参数 $\theta$ 的估计值, 即取 $\hat \theta$ 使 $$L(x_1, x_2, \cdots, x_n; \theta) = \max _{\theta \in \Theta} L(x_1, x_2, \cdots, x_n; \theta)$$ 这样得到的 $\hat \theta$ 与样本值 $x_1,x_2,\cdots,x_n$ 有关, 常记为 $\hat \theta(x_1,x_2,\cdots,x_n)$, 称为参数 $\theta$ 的 **最大似然估计值**, 而相应的统计量 $\hat \theta(X_1, X_2, \cdots, X_n)$ 称为参数 $\theta$ 的 **最大似然估计量**
* 若总体 $X$ 属连续型, 其概率密度为 $f(x;\theta), \theta \in \Theta$ 的形式为已知, $\theta$ 为待估参数, $\Theta$ 是 $\theta$ 可能取值的范围, 设 $X_1, X_2, \cdots, X_n$ 是来自 $X$ 的样本, 则 $X_1, X_2, \cdots, X_n$ 的联合概率密度为 $$\prod _{i=1}^n f(x;\theta)$$ 又设 $x_1, x_2, \cdots, x_n$ 是相应于样本 $X_1, X_2, \cdots, X_n$ 的一个样本值, 则随机点 $(X_1,X_2,\cdots,X_n)$ 落在点 $(x_1,x_2,\cdots,x_n)$ 的邻域内的概率近似的为 $$\prod _{i=1}^n f(x_i;\theta) \mathrm{d}x_i$$ 其值随 $\theta$ 的取值而变化. 与离散型的情况一样, 我们取 $\theta$ 的估计值 $\hat \theta$ 使概率取到最大值, 即 $$L(\theta) = L(x_1, x_2, \cdots, x_n; \theta) = \prod _{i=1}^n f(x;\theta)$$ 的最大值. 这里 $L(\theta)$ 称为样本的 **似然函数**.
    若 $$L(x_1, x_2, \cdots, x_n; \hat \theta) = \max _{\theta \in \Theta} L(x_1, x_2, \cdots, x_n; \theta)$$ 则称 $\hat \theta(x_1,x_2,\cdots,x_n)$, 称为参数 $\theta$ 的 **最大似然估计值**, 而相应的统计量 $\hat \theta(X_1, X_2, \cdots, X_n)$ 称为参数 $\theta$ 的 **最大似然估计量**
* 具体步骤
    1. 列出似然函数: $$L(\theta) = \begin{cases} \displaystyle \prod _{i=1}^n p(x;\theta), & 离散型 \\  \displaystyle \prod _{i=1}^n f(x;\theta), & 连续型 \end{cases}$$
    1. $\theta$ 的最大似然估计可以从 **对数似然方程** $\dfrac{\mathrm{d}}{\mathrm{d}x}\ln L(\theta) = 0$ 求得

### 6.1.3. 常见分布的估计
* 二项分布 $X \sim b(n,p)$ 的最大似然估计: $$\hat p = \bar X$$
* 均匀分布 $X \sim U(a,b)$ 的矩估计: $$\begin{aligned} \hat a &= \bar X - \sqrt {\dfrac{3}{n}\sum _{i=1}^n(X_i - \bar X)^2 } \\ \hat b &= \bar X + \sqrt {\dfrac{3}{n}\sum _{i=1}^n(X_i - \bar X)^2 }\end{aligned}$$
    * 最大似然估计: $$\begin{aligned} \hat a &= \displaystyle \min _{1\leqslant i \leqslant n}X_i \\ \hat b &= \displaystyle \max _{1\leqslant i \leqslant n}X_i\end{aligned}$$
* 高斯分布  $X \sim N(\mu, \sigma^2)$ 的估计: $$\begin{aligned} \hat u &= \bar X \\ \hat {\sigma^2} &= \dfrac{1}{n}\sum _{i=1}^n(X_i - \bar X)^2 \end{aligned}$$

## 6.2. 估计量的评选标准
* 无偏性
    * 设 $X_1,X_2,\cdots,X_n$ 是总体 $X$ 的一个样本, $\theta \in \Theta$ 是包含在总体 $X$ 的分布中的待估参数, $\Theta$ 是 $\theta$ 的取值范围. 若估计量 $\hat \theta = \hat \theta(X_1, X_2, \cdots, X_n)$ 的数学期望 $E(\hat \theta)$ 存在, 且对于任意 $\theta \in \Theta$ 有 $$E(\hat \theta) = \theta$$ 则称 $\hat \theta$ 是 $\theta$ 的 **无偏估计量**
* 有效性
    * 设 $\hat \theta_1 = \hat \theta_1 (X_1,X_2,\cdots,X_n)$ 与 $\hat \theta_2 = \hat \theta_2 (X_1,X_2,\cdots,X_n)$ 都是 $\theta$ 的无偏估计量, 若对于任意 $\theta \in \Theta$ 有 $$D(\hat \theta_1) \leqslant D(\hat \theta_2)$$ 且至少对于某一个 $\theta \in \Theta$ 上式中的不等号成立, 则称 $\hat \theta_1$ 较 $\hat \theta_2$ **有效**
* 相合性
    * 设 $\hat \theta (X_1,X_2,\cdots,X_n)$ 为参数 $\theta$ 的估计量, 若对于任意 $\theta \in \Theta$, 当 $n \to \infin$ 时 $\hat \theta (X_1,X_2,\cdots,X_n)$ 依概率收敛于 $\theta$, 则称 $\hat \theta$ 为 $\theta$ 的 **相合估计量**
    * 即, 若对于任意 $\theta \in \Theta$ 都满足: 对于任意 $\varepsilon > 0$, 有 $$\lim _{n \to \infin} P \{|\hat \theta - \theta| < \varepsilon\} = 1$$ 则称 $\hat \theta$ 为 $\theta$ 的 **相合估计量**

## 6.3. 区间估计
### 6.3.1. 置信区间
* 定义: 设总体 $X$ 的分布函数 $F(x;\theta)$ 含有一个未知参数 $\theta, \theta \in \Theta$, $\Theta$ 是 $\theta$ 可能取值的范围, 对于给定值 $\alpha(0<\alpha<1)$, 若由来自 $X$ 的样本 $X_1,X_2,\cdots, X_n$ 确定的两个统计量 $\underline \theta = \underline \theta(X_1,X_2,\cdots,X_n)$ 和 $\bar \theta = \bar \theta(X_1,X_2,\cdots,X_n)$ $(\underline \theta < \bar \theta)$ 对于任意 $\theta \in \Theta$ 满足 $$P\{\underline \theta(X_1,X_2,\cdots,X_n) < \theta <\bar \theta = \bar \theta(X_1,X_2,\cdots,X_n)\} \geqslant 1-\alpha$$ 则称随机区间 $(\underline \theta, \bar \theta)$ 是 $\theta$ 的置信水平为 $1-\alpha$ 的 **置信区间**, $\underline \theta$ 和 $\bar \theta$ 分别称为置信水平为 $1-\alpha$ 的双侧置信区间的 **置信下限** 和 **置信上限**, $1-\alpha$ 称为 **置信水平**
* 求置信区间的具体做法
    1. 寻求一个样本 $X_1, X_2, \cdots, X_n$ 和 $\theta$ 的函数 $W=W(X_1,X_2,\cdots,X_n; \theta)$, 使得 $W$ 的分布不依赖于 $\theta$ 以及其他位置参数, 称具有这种性质的函数 $W$ 为 **枢轴量**
    1. 对于给定的置信水平 $1-\alpha$, 定出两个参数 $a,b$ 使得 $$P\{a < W(X_1,X_2,\cdots,X_n) < b\} = 1-\alpha$$ 若能从 $a < W(X_1,X_2,\cdots,X_n) < b$ 得到与之等价的 $\theta$ 的不等式 $\underline \theta < \theta < \bar \theta$, 那么 $(\underline \theta, \bar \theta)$ 就是 $\theta$ 的一个置信区间

### 6.3.2. 单侧置信区间
* 对于给定值 $\alpha(0<\alpha<1)$, 若由样本 $X_1,X_2,\cdots, X_n$ 确定的统计量 $\underline \theta = \underline \theta(X_1,X_2,\cdots,X_n)$ 对于任意 $\theta \in \Theta$ 满足 $$P\{\theta > \underline \theta\} \geqslant 1-\alpha$$ 则称随机区间 $(\underline \theta, \infin)$ 是 $\theta$ 的置信水平为 $1-\alpha$ 的 **单侧置信区间**, $\underline \theta$ 称为置信水平为 $1-\alpha$ 的双侧置信区间的 **单侧置信下限**
* 又若统计量 $\bar \theta = \bar \theta(X_1,X_2,\cdots,X_n)$ 对于任意 $\theta \in \Theta$ 满足 $$P\{\theta < \bar \theta\} \geqslant 1-\alpha$$ 则称随机区间 $(-\infin, \bar \theta)$ 是 $\theta$ 的置信水平为 $1-\alpha$ 的 **单侧置信区间**, $\bar \theta$ 称为置信水平为 $1-\alpha$ 的双侧置信区间的 **单侧置信上限**

### 6.3.3. 正态总体的区间估计
* 单个总体 $N(\mu, \sigma^2)$ 的情况
    设已给定置信水平为 $1-\alpha$, 并设 $X_1,X_2,\cdots,X_n$ 为总体 $N(\mu, \sigma^2)$ 的样本. $\bar X, S^2$ 分别是样本的均值和样本方差

    待估参数 | 其他参数 | 枢轴量的分布 | 置信区间 | 单侧置信区间
    :------: | :------: | :----------: | :------: | :----------: |
    $\mu$    | $\sigma^2$ 已知 | $Z = \dfrac{\bar X - \mu}{\sigma / \sqrt n} \sim N(0,1)$ | $(\bar X \pm \dfrac{\sigma}{\sqrt n}z_{\alpha/2})$ | $\overline \mu = \bar X + \dfrac{\sigma}{\sqrt n}z_{\alpha}, \\ \ \\ \underline \mu = \bar X - \dfrac{\sigma}{\sqrt n}z_{\alpha}$
    ^        | $\sigma^2$ 未知 | $t = \dfrac{\bar X - \mu}{S / \sqrt n} \sim t(n-1)$ | $\Big(\bar X \pm \dfrac{S}{\sqrt n}t_{\alpha/2}(n-1)\Big)$ | $\overline \mu = \bar X + \dfrac{S}{\sqrt n}t_{\alpha}(n-1), \\ \ \\ \underline \mu = \bar X - \dfrac{S}{\sqrt n}t_{\alpha}(n-1)$
    $\sigma^2$ | $\mu$ 未知 | $\chi^2 = \dfrac{(n-1)S^2}{\sigma^2} \sim \chi^2(n-1)$ | $\Big(\dfrac{(n-1)S^2}{\chi^2_{\alpha/2}(n-1)}, \dfrac{(n-1)S^2}{\chi^2_{1-\alpha/2}(n-1)}\Big)$ | $\overline {\sigma^2} = \dfrac{(n-1)S^2}{\chi^2_{1-\alpha}(n-1)}, \\ \ \\ \underline {\sigma^2} = \dfrac{(n-1)S^2}{\chi^2_{\alpha}(n-1)}$

* 两个总体 $N(\mu_1, \sigma_1^2), N(\mu_2, \sigma_2^2)$ 的情况

    待估参数 | 其他参数 | 枢轴量的分布 | 置信区间 | 单侧置信区间
    :------: | :------: | :----------: | :------: | :-----------
    $\mu_1 -\mu_2$ | $\sigma_1^2, \sigma_2^2$ 已知 | $Z = \dfrac{\bar X - \bar Y -(\mu_1 - \mu_2)}{\sqrt {\dfrac{\sigma_1^2}{n_1} + \dfrac{\sigma_2^2}{n_2}}} \\ \ \\ \sim N(0,1)$ | $\Big(\bar X - \bar Y \pm z_{\alpha/2} \sqrt {\dfrac{\sigma_1^2}{n_1} + \dfrac{\sigma_2^2}{n_2}}\Big)$ | $\overline {\mu_1 -\mu_2} = \bar X - \bar Y + z_{\alpha} \sqrt {\dfrac{\sigma_1^2}{n_1} + \dfrac{\sigma_2^2}{n_2}}\\ \ \\\underline {\mu_1 -\mu_2} = \bar X - \bar Y - z_{\alpha} \sqrt {\dfrac{\sigma_1^2}{n_1} + \dfrac{\sigma_2^2}{n_2}}$
    ^ | $\sigma_1 = \sigma_2 = \sigma^2$ 未知 | $t = \dfrac{\bar X - \bar Y - (\mu_1 - \mu_2)}{S_\omega \sqrt {\dfrac{1}{n_1} + \dfrac{1}{n_2}}} \\ \ \\ \sim t(n_1+n_2-2)\\ \ \\ S_\omega^2 = \dfrac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1 + n_2 -2}$ | $\Big(\bar X - \bar Y \pm t_{\alpha/2} (n_1+n_2-2)S_\omega \sqrt {\dfrac{1}{n_1} + \dfrac{1}{n_2}}\Big)$ | $\overline {\mu_1 -\mu_2} = \bar X - \bar Y + t_{\alpha} (n_1+n_2-2)S_\omega \sqrt {\dfrac{1}{n_1} + \dfrac{1}{n_2}}\\ \ \\ \underline {\mu_1 -\mu_2} = \bar X - \bar Y - t_{\alpha} (n_1+n_2-2)S_\omega \sqrt {\dfrac{1}{n_1} + \dfrac{1}{n_2}}$
    $\dfrac {\ \sigma_1^2 \ }{\sigma_2^2}$ | $\mu_1, \mu_2$ 未知 | $F = \dfrac{S_1^2 / S_2^2}{\sigma_1^2 / \sigma_2^2} \\ \ \\ \sim F(n_1-1, n_2-1)$ | $\Big(\dfrac{S_1^2}{S_2^2} \dfrac{1}{F_{\alpha/2}(n_1-1, n_2-1)}, \\ \dfrac{S_1^2}{S_2^2} \dfrac{1}{F_{1-\alpha/2}(n_1-1, n_2-1)} \Big )$ | $\overline {\dfrac {\ \sigma_1^2 \ }{\sigma_2^2}} = \dfrac{S_1^2}{S_2^2} \dfrac{1}{F_{1-\alpha}(n_1-1, n_2-1)}\\ \ \\ \underline {\dfrac {\ \sigma_1^2 \ }{\sigma_2^2}} = \dfrac{S_1^2}{S_2^2} \dfrac{1}{F_\alpha(n_1-1, n_2-1)}$

--------------------------------------------------------------------------------
# 7. 假设检验

## 7.1. 基本概念
* **假设检验**: 先对总体参数提出一个假设值, 然后利用样本信息判断这一假设是否成立
* 假设检验的**假设**:
    * 由定义可知, 我们需要对结果进行假设, 然后拿样本数据去验证这个假设.
    * 一种叫 **原假设**, 也叫**零假设**, 一般是统计者想要拒绝的假设, 用 $H_0$ 表示;
    * 一种叫 **备择假设**, 一般是统计者想要接受的假设, 用 $H_1$ 表示
    * 例如, 以平均值作为假设检验的标准, 可有以下几种形式:
        1. $H_0: \mu = \mu_0, H_1: \mu \ne \mu_0$: **双边假设检验**
        1. $H_0: \mu \leqslant \mu_0, H_1: \mu > \mu_0$: **右边检验**
        1. $H_0: \mu \geqslant \mu_0, H_1: \mu < \mu_0$: **左边检验**
* 假设检验的错误:
    * 第 $I$ 类错误 - "弃真": 在 $H_0$ 为真时拒绝 $H_0$ 的错误
    * 第 $II$ 类错误 - "取伪": 在 $H_0$ 不真时接受 $H_0$ 的错误
    > 应尽量使两类错误都较小, 但样本容量固定时, 若减小第一类错误的概率, 则第二类错误的概率往往升高; 一般来说, 总是控制第一类错误的概率.
    * 只对犯第 $I$ 类错误的概率加以控制, 而不考虑犯第 $II$ 类错误的概率的检验, 称为 **显著性检验**
* **显著性水平**
    * 指当原假设实际上正确时, 检验统计量落在拒绝域的概率, 简单理解就是犯弃真错误的概率
    * 这个值是做假设检验之前统计者根据业务情况定好的
    * 显著性水平α越小, 犯第I类错误的概率自然越小, 一般取值：0.01、0.05、0.1等
* **检验统计量**
    * 据以对原假设和备择假设作出决策的某个样本统计量, 称为检验统计量。
* **拒绝域** 和 **临界点**
    * 当检验统计量取某个区域 $C$ 中的值时, 拒绝原假设 $H_0$, 则称区域 $C$ 为 **拒绝域**
    * 拒绝域的边界点称为 **临界点**

## 7.2. 基本步骤
1. 根据实际问题的要求, 提出原假设 $H_0$ 和备择假设 $H_1$
1. 给定显著性水平 $\alpha$ 以及样本容量 $n$
1. 确定检验统计量以及拒绝域的形式
1. 按 $P\{当 H_0 为真拒绝 H_0\} \leqslant \alpha$ 求出拒绝域
1. 取样, 根据样本观察值做出决策, 是接受 $H_0$ 还是拒绝 $H_0$

## 7.3. 正态总体的假设检验
原假设 $H_0$ | 检验统计量 | 备择假设 $H_1$ | 拒绝域
:----------: | :--------: | :------------: | :----:
$\mu \leqslant \mu_0 \\ \mu \geqslant \mu_0 \\ \mu = \mu_0$ </br> ($\sigma^2$ 已知) | $Z = \dfrac{\bar X - \mu _0}{\sigma / \sqrt n}$ | $\mu > \mu_0 \\ \mu < \mu_0 \\ \mu \ne \mu_0$ | $z \geqslant z_{\alpha} \\ z \leqslant -z_{\alpha} \\ \vert z \vert \geqslant z_{\alpha/2}$
$\mu \leqslant \mu_0 \\ \mu \geqslant \mu_0 \\ \mu = \mu_0$ </br> ($\sigma^2$ 未知) | $t = \dfrac{\bar X - \mu _0}{S / \sqrt n}$ | $\mu > \mu_0 \\ \mu < \mu_0 \\ \mu \ne \mu_0$ | $t \geqslant t_{\alpha}(n-1) \\ t \leqslant -t_{\alpha}(n-1) \\ \vert t \vert\geqslant t_{\alpha/2}(n-1)$
$\mu_1 -\mu_2 \leqslant \delta \\ \mu_1 - \mu_2 \geqslant \delta \\ \mu_1 - \mu_2 = \delta$ </br> ($\sigma_1^2, \sigma_2^2$ 未知) | $Z = \dfrac{\bar X - \bar Y - \delta}{\sqrt {\dfrac{\sigma_1^2}{n_1} + \dfrac{\sigma_2^2}{n_2}}} $ | $\mu_1 -\mu_2 > \delta \\ \mu_1 - \mu_2 < \delta \\ \mu_1 -\mu_2 \ne \delta$ | $z \geqslant z_{\alpha} \\ z \leqslant -z_{\alpha} \\ \vert z \vert \geqslant z_{\alpha/2}$
$\mu_1 -\mu_2 \leqslant \delta \\ \mu_1 - \mu_2 \geqslant \delta \\ \mu_1 - \mu_2 = \delta$ </br> ($\sigma_1 = \sigma_2 = \sigma^2$ 未知) | $t = \dfrac{\bar X - \bar Y - \delta}{S_\omega \sqrt {\dfrac{1}{n_1} + \dfrac{1}{n_2}}} \\ \ \\ S_\omega^2 = \dfrac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1 + n_2 -2}$ | $\mu_1 -\mu_2 > \delta \\ \mu_1 - \mu_2 < \delta \\ \mu_1 -\mu_2 \ne \delta$ | $t \geqslant t_\alpha(n_1 + n_2 -2) \\ t \leqslant -t_\alpha(n_1 + n_2 -2) \\ \vert t \vert \geqslant t_{\alpha/2}(n_1 + n_2 -2) $
$\sigma^2 \leqslant \sigma_0^2 \\ \sigma^2 \geqslant \sigma_0^2 \\ \sigma^2 = \sigma_0^2$ </br> ($\mu$ 未知) | $\chi^2 = \dfrac{(n-1)S^2}{\sigma_0^2}$ | $\sigma^2 > \sigma_0^2 \\ \sigma^2 < \sigma_0^2 \\ \sigma^2 \ne \sigma_0^2$ | $\chi^2 \geqslant \chi^2_\alpha(n-1) \\ \chi^2 \leqslant \chi^2_{1-\alpha}(n-1) \\ \ \\ \chi^2 \geqslant \chi^2_{\alpha/2}(n-1) \ or \\ \chi^2 \leqslant \chi^2_{1-\alpha/2}(n-1)$
$\sigma_1^2 \leqslant \sigma_2^2 \\ \sigma_1^2 \geqslant \sigma_2^2 \\ \sigma_1^2 = \sigma_2^2$ </br> ($\mu_1, \mu_2$ 未知) | $F = \dfrac{S_1^2}{S_2^2}$ | $\sigma_1^2 > \sigma_2^2 \\ \sigma_1^2 < \sigma_2^2 \\ \sigma_1^2 \ne \sigma_2^2$ | $F \geqslant F_\alpha(n_1-1, n_2-1) \\ F \leqslant F_{1-\alpha}(n_1-1,n_2-1) \\ \ \\ F \geqslant F_{\alpha/2}(n_1-1,n_2-1) \ or \\ F \leqslant F_{1-\alpha/2}(n_1-1,n_2-1)$
$\mu_D \leqslant 0 \\ \mu_D \geqslant 0 \\ \mu_D = 0$ </br> (成对数据) | $t = \dfrac{\bar D}{S_D/ \sqrt n}$ | $\mu_D > 0 \\ \mu_D < 0 \\ \mu_D \ne 0$ | $t \geqslant t_{\alpha}(n-1) \\ t \leqslant -t_{\alpha}(n-1) \\ \vert t \vert \geqslant t_{\alpha/2}(n-1)$

## 7.4. 样本容量的选取
> 犯第 $II$ 类错误的概率依赖于样本容量的选择
* **定义**: 若 $C$ 是参数 $\theta$ 的某检验问题的一个检验法, $$\beta (\theta) = P_\theta\{接受 H_0\}$$ 称为检验法 $C$ 的 **施行特征函数** 或 $OC$ 函数, 其图形称为 **OC 曲线**,
    * 当真值 $\theta \in H_0$ 时, $\beta (\theta)$ 就是做出正确判断的概率, 故此时 $\beta (\theta) \geqslant 1-\alpha$
    * 当 $\theta \in H_1$ 时,  $\beta (\theta)$ 是犯第 $II$ 类错误的概率, $1 - \beta (\theta)$ 是做出正确判断的概率
    * $1-\beta(\theta)$ 称为检验法 $C$ 的 **功效函数**, 当 $\theta^* \in H_1$ 时, $1-\beta(\theta^*)$ 称为检验法 $C$ 在 $\theta^*$ 的 **功效**
* $Z$ 检验法的 $OC$ 函数
    * 右边检验问题 $H_0: \mu \leqslant \mu_0, H_1: \mu > \mu_0$ 的 $OC$ 函数是 $$\beta (\mu) = P_\mu \Big\{\dfrac{\bar X - \mu_0}{\sigma / \sqrt n} < z_\alpha\Big\} = \Phi (z_\alpha - \lambda), \quad \lambda = \dfrac{\mu - \mu_0}{\sigma / \sqrt n}$$
        * 性质:
            1. 它是 $\lambda$ 的单调递减连续函数
            1. $\displaystyle \lim _{\mu \to \mu_0^+} \beta(\mu) = 1 - \alpha, \lim _{\mu \to \infin} \beta(\mu) = 0$
        * 只要 $\sqrt n \geqslant \dfrac{(z_\alpha + z_\beta)\sigma}{\delta}$ 就能使当 $\mu \in H_1$ 且 $\mu \geqslant \mu_0 + \delta$ 时 (即真值 $\mu \geqslant \mu_0 + \delta$ 时) 犯第 $II$ 类错误的概率不超过 $\beta$
    * 左边检验问题 $H_0: \mu \geqslant \mu_0, H_1: \mu < \mu_0$ 的 $OC$ 函数是 $$\beta (\mu) = \Phi (z_\alpha + \lambda), \quad \lambda = \dfrac{\mu - \mu_0}{\sigma / \sqrt n}$$
        * 只要 $\sqrt n \geqslant \dfrac{(z_\alpha + z_\beta)\sigma}{\delta}$ 就能使当 $\mu \in H_1$ 且 $\mu \leqslant \mu_0 - \delta \quad (\delta > 0)$ 时, 犯第 $II$ 类错误的概率不超过 $\beta$
    * 双边检验问题 $H_0: \mu = \mu_0, H_1: \mu \ne \mu_0$ 的 $OC$ 函数是 $$\beta (\mu) = \Phi (z_{\alpha/2} - \lambda) - \Phi(-z_{\alpha/2} - \lambda) = \Phi (z_{\alpha/2} - \lambda) + \Phi (z_{\alpha/2} + \lambda) - 1, \quad \lambda = \dfrac{\mu - \mu_0}{\sigma / \sqrt n}$$
        * $\beta(\mu)$ 是 $|\lambda|$ 的严格单调下降函数
        * 只要 $\sqrt n \geqslant (z_{\alpha/2} + z_\beta) \dfrac{\sigma}{\delta}$ 就能使当 $\mu \in H_1$ 且 $|\mu - \mu_0| \geqslant \delta \quad (\delta > 0)$ 时, 犯第 $II$ 类错误的概率不超过 $\beta$
* $t$ 检验的 $OC$ 函数
    * 右边检验问题 $H_0: \mu \leqslant \mu_0, H_1: \mu > \mu_0$ 的 $OC$ 函数是 $$\beta (\mu) = P_\mu \Big\{\dfrac{\bar X - \mu_0}{S / \sqrt n} < t_\alpha(n-1)\Big\}$$ 其中 $$\dfrac{\bar X - \mu_0}{S / \sqrt n} = \Big(\dfrac{\bar X - \mu}{\sigma / \sqrt n} + \lambda\Big)/\Big(\dfrac{S}{\sigma}\Big), \quad \lambda = \dfrac{\mu - \mu_0}{\sigma / \sqrt n}$$
        * $\dfrac{\bar X - \mu_0}{S / \sqrt n}$ 服从非中心参数为 $\lambda$, 自由度为 $n-1$ 的非中心 $t$ 分布
        * 若给定 $\alpha, \beta$ 以及 $\delta > 0$ 可确定容量 $n$, 使当 $\mu \in H_1$ 且 $\dfrac{\mu -\mu_0}{\sigma} \geqslant \delta$ 时犯第 $II$ 类错误的概率不超过 $\beta$
    * 左边检验问题 $H_0: \mu \geqslant \mu_0, H_1: \mu < \mu_0$
        * 若给定 $\alpha, \beta$ 以及 $\delta > 0$ 可确定容量 $n$, 使当 $\mu \in H_1$ 且 $\dfrac{\mu -\mu_0}{\sigma} \leqslant -\delta$ 时犯第 $II$ 类错误的概率不超过 $\beta$
    * 双边检验问题 $H_0: \mu = \mu_0, H_1: \mu \ne \mu_0$
        * 若给定 $\alpha, \beta$ 以及 $\delta > 0$ 可确定容量 $n$, 使当 $\mu \in H_1$ 且 $\dfrac{|\mu -\mu_0|}{\sigma} \geqslant \delta$ 时犯第 $II$ 类错误的概率不超过 $\beta$

## 7.5. 分布拟合检验
### 7.5.1. 单个分布的 $\chi^2$ 拟合检验法
* 设总体 $X$ 的分布未知, $x_1, x_2, \cdots, x_n$ 是来自总体 $X$ 的样本值, 假设
    * $H_0$: 总体 $X$ 的分布函数为 $F(x)$
    * $H_1$: 总体 $X$ 的分布函数不是 $F(x)$

    其中设 $F(x)$ 不含未知参数
* 检验统计量:
    * 把在 $H_0$ 下 $X$ 可能取值的全体 $\Omega$ 分成互不相交的子集 $A_1, A_2, \cdots, A_k$, 用 $f_i(i = 1, 2, \cdots, k)$ 记录样本落在 $A_i$ 中的个数, 于是 $n$ 此实验中事件 $A_i$ 的频率为 $\dfrac{f_i}{n}$. 当 $H_0$ 为真, 且试验次数足够多时, 频率 $\dfrac{f_i}{n}$ 与概率 $p_i$ 的差异不应太大
    * 可以采用 $$\chi^2 = \displaystyle \sum _{i=1}^k \dfrac{n}{p_i}(\dfrac{f_i}{n}-p_i)^2 = \sum _{i=1}^k \dfrac{f_i^2}{np_i}-n$$ 作为检验统计量
* **定理**: 当 $n$ 充分大($n \geqslant 50$), 则当 $H_0$ 为真时统计量 $\chi^2 = \displaystyle \sum _{i=1}^k \dfrac{f_i^2}{np_i}-n$ 近似服从 $\chi^2(k-1)$ 分布
    * 根据定理, 当 $H_0$ 为真时, $\chi^2$ 不应太大, 拒绝域的形式为 $$\chi^2 \geqslant \chi^2_{\alpha}(k-1)$$

### 7.5.2. 分布族的 $\chi^2$ 拟合检验
* 多数情况下, $F(x)$ 未知, 原假设变为
    * $H_0$: 总体 $X$ 的分布函数为 $F(x; \theta_1, \theta_2, \cdots, \theta_r)$

    其中 $F$ 的形式已知, 而 $\theta = (\theta_1, \theta_2, \cdots, \theta_r)$ 是未知参数
* 检验统计量: 用 $\hat p_i$ 代替 $p_i$, 取 $\chi^2 = \displaystyle \sum _{i=1}^k \dfrac{f_i^2}{n \hat p _i}-n$ 作为统计量
* 在某些条件下, 在 $H_0$ 为真时近似的有 $$\chi^2 = \displaystyle \sum _{i=1}^k \dfrac{f_i^2}{n \hat p _i}-n \sim \chi^2(k-r-1)$$
    > 自由度减小了 $r$, 这是因为需要估计 $r$ 个参数, 如泊松分布要估计 $\lambda$, 则 $r=1$, 而正态分布中需要估算 $(\mu, \sigma^2)$, 则 $r=2$
* 拒绝域的形式为 $$\chi^2 \geqslant \chi^2_{\alpha}(k-r-1)$$

### 7.5.3. 偏度、峰度检验
> 在正态性检验方法中, 总体来说, "偏度、峰度检验法" 和 "夏皮罗-威尔克法" 较有效
* 随机变量 $X$ 的偏度和峰度指的是 $X$ 标准化变量 $\dfrac{X-E(X)}{\sqrt {D(X)}}$ 的三阶矩和四阶矩 $$\begin{aligned}
        \nu_1 = E \Big [\Big(\dfrac{X-E(X)}{\sqrt{D(X)}}\Big)^3\Big]  = \dfrac{E[(X-E(X))^3]}{(D(X))^{3/2}}\\
        \nu_2 = E \Big [\Big(\dfrac{X-E(X)}{\sqrt{D(X)}}\Big)^4\Big]  = \dfrac{E[(X-E(X))^4]}{(D(X))^2}
    \end{aligned}$$
* 当随机变量 $X$ 服从正态分布时 $\nu_1 = 0, \nu_2 = 3$
* 设 $X_1, X_2, \cdots, X_n$ 是来自 $X$ 的样本, 则 $\nu_1, \nu_2$ 的矩估计量分别是 $$G_1 = \dfrac{B_3}{B_2^{3/2}}, \quad G_2 = \dfrac{B_4}{B_2^2}$$ 其中 $B_k \ (k=2,3,4)$ 是样本的中心距, 并分别称 $G_1, G_2$ 为样本偏度和样本峰度
* 若总体 $X$ 是正态分布, 则当 $n$ 充分大时, 近似地有, $$\begin{aligned}
        G_1 & \sim N(0, \dfrac{6(n-2)}{(n+1)(n+3)}) \\
        G_2 & \sim N(3 - \dfrac{6}{n+1}, \dfrac{24 n (n-2)(n-3)}{(n+1)^2(n+3)(n+5)})
    \end{aligned}$$
    * 记 $$\begin{aligned}
            \sigma_1 &= \sqrt {\dfrac{6(n-2)}{(n+1)(n+3)}} \\
            \sigma_1 &= \sqrt {\dfrac{24 n (n-2)(n-3)}{(n+1)^2(n+3)(n+5)}} \\
            \mu_2 &= 3 - \dfrac{6}{n+1} \\
            U_1 &= \dfrac{G_1}{\sigma_1} \\
            U_2 &= \dfrac{(G_2 - \mu_2)}{\sigma_2}
        \end{aligned}$$ 则 $U_1 \sim N(0,1), U_2 \sim N(0,1)$
* 拒绝域: $$|u_1| \geqslant z_{\alpha/4} \quad 或 \quad |u_2| \geqslant z_{\alpha/4}$$ 其中 $u_1, u_2$ 分别是 $U_1, U_2$ 的观察值

## 7.6. 检验问题的 $p$ 值法
* **定义**: 假设检验问题的 **$p$ 值** (probability value) 是由检验统计量的样本观察值得出的原假设可被拒绝的最小显著性水平
* 任一检验问题的 $p$ 值可以根据检验统计量的样本观察值以及检验统计量在 $H_0$ 下一个特定的参数值对应的分布求出
    * 例如, 在正态总体均值的检验中, 当 $\sigma$ 未知时, 可采用检验统计量 $t = \dfrac{\bar X - \mu_0}{S/\sqrt n}$, 当 $\mu = \mu_0$ 时 $t \sim t(n-1)$. 如果由样本求得统计量 $t$ 的观察值 $t_0$, 那么在检验问题
        * $H_0: \mu \leqslant \mu_0, H_1: \mu > \mu_0$ 中, $p = P_{\mu_0}\{t \geqslant t_0\} = t_0$ 右侧尾部面积
        * $H_0: \mu \geqslant \mu_0, H_1: \mu < \mu_0$ 中, $p = P_{\mu_0}\{t \leqslant t_0\} = t_0$ 左侧尾部面积
        ![p值](/assets/概率与统计-p值-1.png)
        * $H_0: \mu = \mu_0, H_1: \mu \ne \mu_0$ 中
            * 当 $t > 0$ 时, $p = P_{\mu_0}\{|t| \geqslant t_0\} = 2 \times t_0$ 右侧尾部面积
            * 当 $t < 0$ 时, $p = P_{\mu_0}\{|t| \geqslant -t_0\} = 2 \times t_0$ 左侧尾部面积
        ![p值](/assets/概率与统计-p值-2.png)
* 按 $p$ 值的定义, 对于任意指定的显著性水平 $\alpha$, 就有
    * 若 $p \leqslant \alpha$, 则拒绝 $H_0$
    * 若 $p > \alpha$, 则接受 $H_0$
* $p$ 值越小, 反对 $H_0$ 的依据越强
    * $p \leqslant 0.01$, 检验是高度显著的
    * $0.01 < p \leqslant 0.05$, 检验是显著的
    * $0.05 < p \leqslant 0.1$, 检验是不显著的
    * $p > 0.1$, 一般来说没有理由拒绝 $H_0$

--------------------------------------------------------------------------------
# 8. 方差分析及线性回归
* **定义**: 影响试验指标的条件称为**因素**, 因素所处的状态称为**水平**

## 8.1. 单因素实验的方差分析
* 设因素 $A$ 有 $s$ 个水平 $A_1, A_2, \cdots, A_s$, 在水平 $A_j(j=1,2,\cdots,s)$ 下, 进行 $n_j(j \geqslant 2)$ 次独立实验, 得到以下试验结果
    水平     | $A_1$              | $A_2$              | $\cdots$ | $A_j$
    :------- | :----------------: | :----------------: | :------: | :------:
    观察结果 | $X_{11}$           | $X_{12}$           | $\cdots$ | $X_{1s}$
    ^        | $X_{21}$           | $X_{22}$           | $\cdots$ | $X_{2s}$
    ^        | $\cdots$           |
    ^        | $X_{n_11}$         | $X_{n_21}$         | $\cdots$ | $X_{n_ss}$
    样本总和 | $T_{\cdot 1}$      | $T_{\cdot 2}$      | $\cdots$ | $T_{\cdot s}$
    样本均值 | $\bar X_{\cdot 1}$ | $\bar X_{\cdot 2}$ | $\cdots$ | $\bar X_{\cdot s}$
    总体均值 | $\mu_1$            | $\mu_2$            | $\cdots$ | $\mu_s$

* 假定各个水平下的样本来自具有相同方差 $\sigma^2$, 均值分别是 $\mu_j \ (j=1,2,\cdots,s)$ 的正态总体 $N(\mu_j, \sigma^2)$, $\mu_j$ 与 $\sigma^2$ 未知, 且设不同水平下的样本相互独立, 则 $X_{ij}$ 可写作 $$\begin{cases} X_{ij} = \mu_j + \varepsilon_{ij} \\ \varepsilon_{ij} \sim N(0, \sigma^2), 各\varepsilon_{ij}独立 \\ i = 1,2,\cdots, n_j; \ j=1,2,\cdots, s \end{cases}$$
* 方差分析的任务是
    1. 检验 $s$ 个总体 $N(\mu_1, \sigma^2), N(\mu_2, \sigma^2), \cdots, N(\mu_s, \sigma^2)$ 均值是否相等, 即检验假设 $$\begin{aligned} H_0 &:  \mu_1 = \mu_2 = \cdots = \mu_s \\ H_1 &: \mu_1, \mu_2, \cdots, \mu_s 不全相等 \end{aligned}$$
    1. 做出未知参数 $\mu_1, \mu_2, \cdots, \mu_s, \sigma^2$ 的估计

* 将 $\mu_1, \mu_2, \cdots, \mu_s$ 的加权平均值 $\dfrac{1}{n}\displaystyle \sum_{j=1}^s n_j \mu_j$ 记作 $\mu$, 称为**总平均** (其中 $n=\displaystyle \sum_{j=1}^s n_j$), 再引入 $\delta_j = \mu_j - \mu \ (j = 1,2,\cdots, s)$ 表示水平 $A_j$ 下总体平均值与总平均的差异, 称为**效应**, 则 $$\begin{cases} X_{ij} = \mu + \delta_j + \varepsilon_{ij} \\ \varepsilon_{ij} \sim N(0, \sigma^2), 各\varepsilon_{ij}独立 \\ i = 1,2,\cdots, n_j; \ j=1,2,\cdots, s \\ \displaystyle \sum _{j=1}^s n_j \delta_j = 0\end{cases}$$ 检验假设变为  $$\begin{aligned} H_0 &:  \delta_1 = \delta_2 = \cdots = \delta_s = 0\\ H_1 &: \delta_1, \delta_2, \cdots, \delta_s 不全为 0 \end{aligned}$$
* 平方和的分解
    * 引入**总偏差平方和** $S_T = \displaystyle \sum _{j=1}^s \sum _{i=1}^{n_j} (X_{ij} - \bar X)^2$, 其中 $\bar X = \dfrac{1}{n}\displaystyle \sum _{j=1}^s \sum _{i=1}^{n_j} X_{ij}$ 是数据的总平均, $S_T$ 又称总变差, 又记水平 $A_j$ 下样本的平均值为 $\bar X$, 即 $\bar X_{\cdot j} = \dfrac{1}{n_j}\displaystyle \sum _{i=1}^{n_j} X_{ij}$
    * $S_T$ 可分解为 $S_T = S_E + S_A$, 其中 $$\begin{aligned} S_E &= \displaystyle \sum _{j=1}^s \sum _{i=1}^{n_j} (X_{ij} - \bar X_{\cdot j})^2 \\ S_A & = \displaystyle \sum _{j=1}^s \sum _{i=1}^{n_j} (\bar X_{\cdot j} - \bar X)^2 = \sum _{j=1}^s n_j (\bar X{\cdot j} - \bar X)^2 = \sum _{j=1}^s n_j \bar X_{\cdot j}^2 - n \bar X^2 \end{aligned}$$
    * $S_E$ 叫做**误差平方和**, $S_A$ 叫做**效应平方和**
    </br>
    * $\dfrac{S_E}{\sigma^2} \sim \chi^2 (n-s), \ E(S_E) = (n-s)\sigma^2$
    </br>
    * $\dfrac{S_A}{\sigma^2} \sim \chi^2 (s-1), \ E(S_A) = (s-1)\sigma^2 + \displaystyle \sum _{j=1}^s n_j \delta_j^2$
* 不管 $H_0$ 是否为真, $\dfrac{S_E}{n-s}$ 都是 $\sigma^2$ 的无偏估计
* 假设检验问题的拒绝域 $F=\dfrac{S_A/(s-1)}{S_E/(n-s)} \geqslant F_\alpha(s-1, n-s)$
* 单因素方差分析表
    方差来源 | 平方和 | 自由度 | 均方 | $F$ 比 | 拒绝域
    :------: | :----: | :----: | :--: | :----: | :----:
    因素 $A$ | $S_A$  | $s-1$  | $\bar S_A = \dfrac{S_A}{s-1}$ | $F=\dfrac{\bar S_A}{\bar S_E}$ | $F_\alpha(s-1, n-s)$
    误差     | $S_E$  | $n-s$  | $\bar S_E = \dfrac{S_E}{n-s}$ | -
    总和     | $S_T$  | $n-1$  | -

    实际中, 用以下公式计算 $S_T, S_A, S_E$: $$\begin{cases} S_T &= \displaystyle \sum _{j=1}^s \sum _{i=1}^{n_j} X_{ij}^2 - n \bar X ^2  = \sum _{j=1}^s \sum _{i=1}^{n_j} X_{ij}^2 - \dfrac{T_{\cdot \cdot}^2}{n} \\ \\ S_A &= \displaystyle \sum _{j=1}^s n_j \bar X_{\cdot j} ^2 - n\bar X^2 = \sum _{j=1}^s \dfrac{T _{\cdot j}^2}{n_j} - \dfrac{T_{\cdot \cdot}^2}{n} \\ \\S_E &= S_T - S_A \end{cases}$$ 其中 $T_{\cdot j} = \displaystyle \sum _{i=1}^{n_j}X_{ij}, j = 1,2,\cdots,s, \quad T_{\cdot \cdot} = \displaystyle \sum _{j=1}^2 \sum _{i=1}^{n_j} X_{ij}$

## 8.2. 双因素试验的方差分析
### 8.2.1. 双因素等重复试验
* 设有两个因素 $A, B$ 作用于试验的指标, 因素 $A$ 有 $r$ 个水平 $A_1, A_2, \cdots, A_r$, 因素 $B$ 有 $s$ 个水平 $B_1, B_2, \cdots, B_s$, 现对因素 $A,B$ 的水平的每对组合 $(Ai, B_j); i= 1,2,\cdots,r; \ j=1,2,\cdots,s$ 都做 $t(t \geqslant 2)$ 次实验, 得到以下试验结果
    因素 $A$ \ 因素 $B$ | $B_1$ | $B_2$ | $\cdots$ | $B_s$
    :-----------------: | :---: | :---: | :------: | :---:
    $A_1$ | $X_{111}, X_{112}, \cdots, X_{11t}$ | $X_{121}, X_{122}, \cdots, X_{12t}$ | $\cdots$ | $X_{1s1}, X_{1s2}, \cdots, X_{1st}$
    $A_2$ | $X_{211}, X_{212}, \cdots, X_{21t}$ | $X_{221}, X_{222}, \cdots, X_{22t}$ | $\cdots$ | $X_{2s1}, X_{2s2}, \cdots, X_{2st}$
    $\cdots$ |
    $A_r$ | $X_{r11}, X_{r12}, \cdots, X_{r1t}$ | $X_{r21}, X_{r22}, \cdots, X_{r2t}$ | $\cdots$ | $X_{rs1}, X_{rs2}, \cdots, X_{rst}$

    并设 $X_{ijk} \sim N(\mu_{ij}, \sigma^2), \quad i=1,2,\cdots,r; \ j=1,2,\cdots,s; \ k=1,2,\cdots,t$, $X_{ijk}$ 独立
* 方差分析表
    方差来源 | 平方和 | 自由度 | 均方 | $F$ 比 | 拒绝域
    :------: | :----: | :----: | :--: | :----: | :----:
    因素 $A$ | $S_A$  | $r-1$  | $\bar S_A = \dfrac{S_A}{r-1}$ | $F=\dfrac{\bar S_A}{\bar S_E}$ | $F_{\alpha} (r-1,rs(t-1))$
    因素 $B$ | $S_B$  | $s-1$  | $\bar S_B = \dfrac{S_B}{s-1}$ | $F=\dfrac{\bar S_B}{\bar S_E}$ | $F_{\alpha} (s-1,rs(t-1))$
    交互作用 | $S_{A\times B}$ | $(r-1)(s-1)$ | $\bar S_{A \times B} = \dfrac{S_{A \times B}}{(r-1)(s-1)}$ | $F_{A \times B} = \dfrac{\bar S_{A \times B}}{\bar S_E}$ | $F_{\alpha} \Big((r-1)(s-1),rs(t-1)\Big)$
    误差     | $S_E$  | $rs(t-1)$  | $\bar S_E = \dfrac{S_E}{rs(t-1)}$ | -
    总和     | $S_T$  | $rst-1$  | -

    实际中, 用以下公式计算 $S_T, S_A, S_B, S_{A \times B}$: $$\begin{cases}
            S_T &= \displaystyle \sum _ {i=1}^r \sum _ {j=1}^s \sum _ {k=1}^t X_{ijk}^2 - \dfrac{T_{\cdot \cdot \cdot}^2}{rst} \\ \\
            S_A &= \displaystyle \dfrac{1}{st} \sum _ {i=1}^r T _ {i \cdot \cdot}^2 - \dfrac{T_{\cdot \cdot \cdot}^2}{rst} \\ \\
            S_B &= \displaystyle \dfrac{1}{rt} \sum _ {j=1}^s T _ {\cdot j \cdot}^2 - \dfrac{T_{\cdot \cdot \cdot}^2}{rst} \\ \\
            S_{A \times B} &= \Big(\displaystyle \dfrac{1}{t} \sum _ {i=1}^r \sum _ {j=1}^s T _ {i j \cdot}^2 - \dfrac{T_{\cdot \cdot \cdot}^2}{rst}\Big) - S_A - S_B\\ \\
            S_E &= S_T - S_A - S_B - S_{A \times B}
        \end{cases}$$ 其中 $$\begin{aligned}
            T_{\cdot \cdot \cdot} &= \displaystyle \sum _ {i=1}^r \sum _ {j=1}^s \sum _ {k=1}^t X_{ijk} \\
            T_{i j \cdot} &= \displaystyle \sum _ {k=1}^t X_{ijk}, \quad i=1,2,\cdots,r; \ j=1,2,\cdots,s\\
            T_{i \cdot \cdot} &= \displaystyle \sum _ {j=1}^s \sum _ {k=1}^t X_{ijk}, \quad i=1,2,\cdots,r\\
            T_{\cdot j \cdot} &= \displaystyle \sum _ {i=1}^r \sum _ {k=1}^t X_{ijk}, \quad j=1,2,\cdots,s
         \end{aligned}$$

### 8.2.2. 双因素无重复试验
* 设有两个因素 $A, B$ 作用于试验的指标, 因素 $A$ 有 $r$ 个水平 $A_1, A_2, \cdots, A_r$, 因素 $B$ 有 $s$ 个水平 $B_1, B_2, \cdots, B_s$, 现对因素 $A,B$ 的水平的每对组合 $(Ai, B_j); i= 1,2,\cdots,r; \ j=1,2,\cdots,s$ 只做一次实验, 得到以下试验结果
    因素 $A$ \ 因素 $B$ | $B_1$ | $B_2$ | $\cdots$ | $B_s$
    :-----------------: | :---: | :---: | :------: | :---:
    $A_1$         | $X_{11}$ | $X_{12}$ | $\cdots$ | $X_{1s}$
    $A_2$         | $X_{21}$ | $X_{22}$ | $\cdots$ | $X_{2s}$
    $\cdots$      |
    $A_r$         | $X_{r1}$ | $X_{r2}$ | $\cdots$ | $X_{rs}$

    并设 $X_{ij} \sim N(\mu_{ij}, \sigma^2), \quad i=1,2,\cdots,r; \ j=1,2,\cdots,s$, $X_{ij}$ 独立
* 方差分析表
    方差来源 | 平方和 | 自由度 | 均方 | $F$ 比 | 拒绝域
    :------: | :----: | :----: | :--: | :----: | :----:
    因素 $A$ | $S_A$  | $r-1$  | $\bar S_A = \dfrac{S_A}{r-1}$ | $F=\dfrac{\bar S_A}{\bar S_E}$ | $F_{\alpha} \Big(r-1,(r-1)(s-1)\Big)$
    因素 $B$ | $S_B$  | $s-1$  | $\bar S_B = \dfrac{S_B}{s-1}$ | $F=\dfrac{\bar S_B}{\bar S_E}$ | $F_{\alpha} \Big(s-1,(r-1)(s-1)\Big)$
    误差     | $S_E$  | $(r-1)(s-1)$  | $\bar S_E = \dfrac{S_E}{(r-1)(s-1)}$ | -
    总和     | $S_T$  | $rs-1$  | -

    实际中, 用以下公式计算 $S_T, S_A, S_B, S_{A \times B}$: $$\begin{cases}
            S_T &= \displaystyle \sum _ {i=1}^r \sum _ {j=1}^s X_{ij}^2 - \dfrac{T_{\cdot \cdot}^2}{rs} \\ \\
            S_A &= \displaystyle \dfrac{1}{s} \sum _ {i=1}^r T _ {i \cdot}^2 - \dfrac{T_{\cdot \cdot}^2}{rs} \\ \\
            S_B &= \displaystyle \dfrac{1}{r} \sum _ {j=1}^s T _ {\cdot j}^2 - \dfrac{T_{\cdot \cdot}^2}{rs} \\ \\
            S_E &= S_T - S_A - S_B
        \end{cases}$$ 其中 $$\begin{aligned}
            T_{\cdot \cdot} &= \displaystyle \sum _ {i=1}^r \sum _ {j=1}^s X_{ij} \\
            T_{i \cdot} &= \displaystyle \sum _ {j=1}^s X_{ij}, \quad i=1,2,\cdots,r\\
            T_{\cdot j} &= \displaystyle \sum _ {i=1}^r X_{ij}, \quad j=1,2,\cdots,s
         \end{aligned}$$

## 8.3. 一元线性回归
> 直线拟合
* **一元线性回归模型** $Y = a+bx + \varepsilon, \quad \varepsilon \sim N(0,\sigma^2)$
    * $b$ 称为**回归系数**
* **正规方程组** $\begin{cases}
        \displaystyle na + (\sum _{i=1}^n x_i)b = \sum _{i=1}^n y_i \\
        \displaystyle (\sum _{i=1}^n x_i)a + (\sum _{i=1}^n x_i^2)b = \sum _{i=1}^n x_i y_i
     \end{cases}$
* $a, b$ 的最大似然估计值为 $$\begin{aligned}
        \displaystyle \hat b &= \dfrac{\displaystyle n \sum _{i=1}^n x_i y_i -(\sum _{i=1}^n x_i)(\sum _{i=1}^n y_i)}{\displaystyle n \sum _{i=1}^n x_i^2 - (\sum _{i=1}^n x_i)^2} = \dfrac{\displaystyle \sum _{i=1}^n (x_i - \bar x)(y_i - \bar y)}{\displaystyle \sum _{i=1}^n(x_i - \bar x)^2} = \dfrac {S_{xy} }{S_{xx}}\\
        \displaystyle \hat a &= \dfrac{1}{n} \sum _{i=1}^n y_i - \dfrac{\hat b}{n} \sum _{i=1}^n x_i = \bar y - \hat b \bar x
    \end{aligned}$$ 其中 $$\begin{aligned}
        S_{xx} &= \sum _{i=1}^n (x_i - \bar x)^2 = \sum _{i=1}^n x_i^2 - \dfrac{1}{n}(\sum _{i=1}^n x_i)^2 \\
        S_{yy} &= \sum _{i=1}^n (y_i - \bar y)^2 = \sum _{i=1}^n y_i^2 - \dfrac{1}{n}(\sum _{i=1}^n y_i)^2 \\
        S_{xy} &= \sum _{i=1}^n (x_i - \bar x)(y_i - \bar y) = \sum _{i=1}^n x_i y_i - \dfrac{1}{n}(\sum _{i=1}^n x_i)(\sum _{i=1}^n y_i) \\
    \end{aligned}$$
* **回归方程** $\hat y = \hat a + \hat b x$
* **残差**: $y_i - \hat y_i$
* **残差平方和**: $$R^2 = \displaystyle \sum _{i=1}^n (y_i - \hat y_i)^2 = \sum _{i=1}^n (y_i - \hat a - \hat b x_i)^2 = S_{YY} - \hat b S_{xY}$$ 其中 $\displaystyle S_{YY} = \sum _{i=1}^n (Y_i - \bar Y)^2, \quad S_{xY} = \sum _{i=1}^n (x_i - \bar x)(Y_i - \bar Y)$
* $\sigma^2$ 的无偏估计量 $$\hat \sigma^2 = \dfrac{R^2}{n-2}$$
    * $\dfrac{R^2}{\sigma^2} \sim \chi^2(n-2)$
* 线性假设 ($H_0: b = 0, \ H_1: b \ne 0$ ) 的显著性检验
    * $t = \dfrac{\hat b}{\hat \sigma} \sqrt {S_{xx}} \sim t(n-2)$
    * 拒绝域为 $|t| \geqslant t_{\alpha/2}(n-2)$
* 系数 $b$ 的置信区间 $\Big(\hat b \pm t_{\alpha/2}(t-2) \times \dfrac{\hat \sigma}{\sqrt {S_{xx}}}\Big)$
* 可化为一元线性回归的例子
    1. $Y = \alpha \mathrm{e} ^ {\beta x} \cdot \varepsilon, \ln \varepsilon \sim N(0, \sigma^2)$
        * $\ln Y = \ln \alpha + \beta x + \ln \varepsilon$
        * 令 $Y' = \ln Y, a = \ln \alpha, b = \beta, x' = x, \varepsilon' = \ln \varepsilon$, 则一元线性回归模型为 $Y' = a + b x' + \varepsilon', \ \varepsilon' \sim N(0, \sigma^2)$
    1. $Y = \alpha x^\beta \cdot \varepsilon, \ln \varepsilon \sim N(0, \sigma^2)$
        * $\ln Y = \ln \alpha + \beta \ln x + \ln \varepsilon$
        * 令 $Y' = \ln Y, a = \ln \alpha, b = \beta, x' = \ln x, \varepsilon' = \ln \varepsilon$, 则一元线性回归模型为 $Y' = a + b x' + \varepsilon', \ \varepsilon' \sim N(0, \sigma^2)$
    1. $Y = \alpha + \beta h(x) + \varepsilon, \varepsilon \sim N(0, \sigma^2)$
        * 令 $a = \alpha, b = \beta, x' = h(x)$, 则一元线性回归模型为 $Y = a + b x' + \varepsilon, \ \varepsilon \sim N(0, \sigma^2)$

## 8.4. 多元线性回归
* **多元线性回归模型** $Y= b_0 + b_1 x_1 + b_2 x_2 + \cdots + b_p x_p + \varepsilon, \ \varepsilon \sim N(0, \sigma^2)$
* **正规方程组** $\begin{cases}
        \displaystyle b_0 n + b_1 \sum _{i=1}^n x_{i1} + b_2 \sum _{i=1}^n x_{i2} + \cdots + b_p \sum _{i=1}^n x_{ip} = \sum _{i=1}^n y_i \\
        \displaystyle b_0 \sum _{i=1}^n x_{i1} + b_1 \sum _{i=1}^n x_{i1}^2 + b_2 \sum _{i=1}^n x_{i1} x_{i2} + \cdots + b_p \sum _{i=1}^n x_{i1}x_{ip} = \sum _{i=1}^n x_{i1}y_i \\
        \quad \vdots \\
        \displaystyle b_0 \sum _{i=1}^n x_{ip} + b_1 \sum _{i=1}^n x_{ip}x_{i1} + b_2 \sum _{i=1}^n x_{ip} x_{i2} + \cdots + b_p \sum _{i=1}^n x_{ip}^2 = \sum _{i=1}^n x_{ip}y_i \\
     \end{cases}$
* $b_0, b_1, \cdots, b_p$ 的最大似然估计 $$\hat {\bm B} = \begin{pmatrix} \hat b_0 \\ \hat b_1 \\ \vdots \\ \hat b_p \end{pmatrix} = (\bm X^T \bm X)^{-1} \bm X^T \bm Y$$ 其中 $\bm X = \begin{pmatrix}
            1      & x_{11} & x_{12} & \cdots & x_{1p} \\
            1      & x_{21} & x_{22} & \cdots & x_{2p} \\
            \vdots & \vdots & \vdots &        & \vdots \\
            1      & x_{n1} & x_{n2} & \cdots & x_{np} \\
        \end{pmatrix}, \bm Y = \begin{pmatrix}
            y_1 \\
            y_2 \\
            \vdots \\
            y_n \\
        \end{pmatrix} $
* **回归方程** $\hat y = \hat b_0 + \hat b_1 x_1 + \hat b_2 x_2 + \cdots + \hat b_p x_p$

--------------------------------------------------------------------------------

--------------------------------------------------------------------------------
